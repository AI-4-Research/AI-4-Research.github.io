<!DOCTYPE html>
<html>

<head>
        <meta charset="utf-8">
        <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
        <!-- Replace the content tag with appropriate information -->
        <meta name="description" content="DESCRIPTION META TAG">
        <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
        <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
        <meta property="og:url" content="URL OF THE WEBSITE" />
        <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
        <meta property="og:image" content="static/image/your_banner_image.png" />
        <meta property="og:image:width" content="1200" />
        <meta property="og:image:height" content="630" />


        <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
        <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
        <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
        <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
        <meta name="twitter:card" content="summary_large_image">
        <!-- Keywords for your paper to be indexed by-->
        <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
        <meta name="viewport" content="width=device-width, initial-scale=1">


        <title>AI4Research: A Survey of Artificial Intelligence for Scientific Research</title>
        <link rel="icon" type="image/x-icon" href="static/images/icon.jpg">
        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

        <link rel="stylesheet" href="static/css/bulma.min.css">
        <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="static/css/index.css">

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
        <script defer src="static/js/fontawesome.all.min.js"></script>
        <script src="static/js/bulma-carousel.min.js"></script>
        <script src="static/js/bulma-slider.min.js"></script>
        <script src="static/js/index.js"></script>
</head>

<body>



        <section class="hero">
                <div class="hero-body">
                        <div class="container is-max-desktop">
                                <div class="columns is-centered">
                                        <div class="column has-text-centered">
                                                <h1 class="title is-1 publication-title"> <img
                                                                src="static/images/icon.jpg" alt="SVG Image"
                                                                width="80px"> AI4Research: A Survey of Artificial
                                                        Intelligence for Scientific Research</h1>
                                                <div class="is-size-5 publication-authors">
                                                        <!-- Paper authors -->
                                                        <span class="author-block">
                                                                <a href="https://lightchen233.github.io/"
                                                                        target="_blank">Qiguang
                                                                        Chen</a><sup>1*</sup>,</span>
                                                        <span class="author-block">
                                                                <a href="https://jeronimoyang.github.io/"
                                                                        target="_blank">Mingda
                                                                        Yang</a><sup>1*</sup>,</span>
                                                        <span class="author-block">
                                                                <a href="https://faculty.csu.edu.cn/qinlibo/zh_CN/index.htm"
                                                                        target="_blank">Libo Qin</a><sup>2</sup>,</span>
                                                        <span class="author-block">
                                                                <a href="https://github.com/Yzweak"
                                                                        target="_blank">Zheng
                                                                        Yan</a><sup>1</sup>,</span>
                                                        <span class="author-block">
                                                                <a href="https://github.com/jubgjf"
                                                                        target="_blank">Jiannan
                                                                        Guan</a><sup>1</sup>,</span> <!-- 补充链接 -->
                                                        <span class="author-block">
                                                                <a href="https://github.com/sfasfaffa"
                                                                        target="_blank">Dengyun
                                                                        Peng</a><sup>1</sup>,</span> <!-- 补充链接 -->
                                                        <span class="author-block">
                                                                <a href="https://github.com/j-yyyyy"
                                                                        target="_blank">Yiyan Ji</a><sup>1</sup>,</span>
                                                        <!-- 替换 # -->
                                                        <span class="author-block">
                                                                <a href="https://github.com/FarzoneILIN"
                                                                        target="_blank">Jinhao
                                                                        Liu</a><sup>1</sup>,</span>
                                                        <!-- 替换 & -->
                                                        <span class="author-block">
                                                                <a href="https://github.com/Lee1003-lee"
                                                                        target="_blank">Hanjing
                                                                        Li</a><sup>1</sup></span>
                                                        <span class="author-block">
                                                                <a href="https://aaron617.github.io/"
                                                                        target="_blank">Mengkang
                                                                        Hu</a><sup>3</sup></span>
                                                        <span class="author-block">
                                                                <a href="#" target="_blank">Yimeng
                                                                        Zhang</a><sup>4</sup></span>
                                                        <span class="author-block">
                                                                <a href="#" target="_blank">Yihao
                                                                        Liang</a><sup>4</sup></span>
                                                        <span class="author-block">
                                                                <a href="https://github.com/Ralph-Zhou"
                                                                        target="_blank">Yuhang
                                                                        Zhou</a><sup>5</sup></span>
                                                        <span class="author-block">
                                                                <a href="#" target="_blank">Jiaqi
                                                                        Wang</a><sup>6</sup></span>
                                                        <span class="author-block">
                                                                <a href="#" target="_blank">Zhi
                                                                        Chen</a><sup>7</sup></span>
                                                        <span class="author-block">
                                                                <a href="https://chewanxiang.com/"
                                                                        target="_blank">Wanxiang
                                                                        Che</a><sup>1</sup></span>
                                                </div>

                                                <div class="is-size-5 publication-authors">
                                                        <span class="author-block">LARG, Research Center for Social
                                                                Computing and Interactive Robotics, Harbin Institute of
                                                                Technology<sup>1</sup>,</span>
                                                        <span class="author-block">School of Computer Science and
                                                                Engineering, Central South
                                                                University<sup>2</sup>,</span>
                                                        <span class="author-block">The University of Hong
                                                                Kong<sup>3</sup>,</span> <!-- 替换 # -->
                                                        <span class="author-block">Independent
                                                                Researcher<sup>4</sup>,</span>
                                                        <span class="author-block">Fudan University<sup>5</sup>,</span>
                                                        <span class="author-block">Chinese University of Hong
                                                                Kong<sup>6</sup>,</span>
                                                        <span class="author-block">ByteDance Seed
                                                                (China)<sup>7</sup></span>
                                                        <!-- 替换 & -->
                                                </div>

                                                <div class="column has-text-centered">
                                                        <div class="publication-links">
                                                                <!-- Arxiv PDF link -->
                                                                <span class="link-block">
                                                                        <a href="#" target="_blank"
                                                                                class="external-link button is-normal is-rounded is-dark">
                                                                                <span class="icon">
                                                                                        <i class="fas fa-file-pdf"></i>
                                                                                </span>
                                                                                <span>Paper</span>
                                                                        </a>
                                                                </span>

                                                                <!-- Github link -->
                                                                <span class="link-block">
                                                                        <a href="#" target="_blank"
                                                                                class="external-link button is-normal is-rounded is-dark">
                                                                                <span class="icon">
                                                                                        <i class="fab fa-github"></i>
                                                                                </span>
                                                                                <span>Code</span>
                                                                        </a>
                                                                </span>

                                                                <!-- ArXiv abstract Link -->
                                                                <span class="link-block">
                                                                        <a href="#" target="_blank"
                                                                                class="external-link button is-normal is-rounded is-dark">
                                                                                <span class="icon">
                                                                                        <i class="ai ai-arxiv"></i>
                                                                                </span>
                                                                                <span>arXiv</span>
                                                                        </a>
                                                                </span>
                                                        </div>
                                                </div>
                                        </div>
                                </div>
                        </div>
                </div>
        </section>

        <section class="section hero is-light">
                <div class="container is-max-desktop">
                        <div class="columns is-centered has-text-centered">
                                <div class="column is-four-fifths">
                                        <h2 class="title is-3">Abstract</h2>
                                        <div class="content has-text-justified">
                                                <p>
                                                        Recent advancements in artificial intelligence (AI),
                                                        particularly in large language models (LLMs) such as OpenAI-o1
                                                        and DeepSeek-R1, have demonstrated remarkable capabilities in
                                                        complex domains such as logical reasoning and experimental
                                                        coding. Motivated by these advancements, numerous studies have
                                                        explored the application of AI in the innovation process,
                                                        particularly in the context of scientific research. These AI
                                                        technologies primarily aim to develop systems that can
                                                        autonomously conduct research processes across a wide range of
                                                        scientific disciplines. Despite these significant strides, a
                                                        comprehensive survey on AI for Research (AI4Research) remains
                                                        absent, which hampers our understanding and impedes further
                                                        development in this field. To address this gap, we present a
                                                        comprehensive survey and offer a unified perspective on
                                                        AI4Research. Specifically, the main contributions of our work
                                                        are as follows: (1) Systematic taxonomy: We first introduce a
                                                        systematic taxonomy to classify six mainstream tasks in
                                                        AI4Research. (2) New frontiers: Then, we identify key research
                                                        gaps and highlight promising future directions, focusing on the
                                                        rigor and scalability of automated experiments, as well as the
                                                        societal impact. (3) Abundant resources: Finally, we compile a
                                                        wealth of open-source resources, including relevant papers, data
                                                        corpora, and leaderboards. We hope our work will provide the
                                                        research community with quick access to these resources and
                                                        stimulate innovative breakthroughs in AI4Research.
                                                </p>
                                        </div>
                                </div>
                        </div>
                </div>
        </section>
        <section class="hero is-small">
                <div class="hero-body">
                        <div class="container">
                                <div id="results-carousel" class="carousel results-carousel">
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/main.png" alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>

                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/scientific-comprehension.png"
                                                                alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/academic-survey.png"
                                                                alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/scientific-discovery.png"
                                                                alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/academic-writing.png"
                                                                alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/academic-peer-reviewing.png"
                                                                alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/application.png" alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                        <div class="item">
                                                <!-- Your image here -->
                                                <div class="image-container">
                                                        <img src="static/images/future.png" alt="MY ALT TEXT" />
                                                </div>
                                                <h2 class="subtitle has-text-centered">
                                                </h2>
                                        </div>
                                </div>
                        </div>
                </div>
        </section>

        <style>
                /* Center the carousel and images */
                .carousel {
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        flex-wrap: wrap;
                }

                /* Ensure all images have the same height */
                .image-container {
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        height: 510px;
                        /* Adjusted to double the height (from 300px to 600px) */
                        overflow: hidden;
                }

                .image-container img {
                        width: auto;
                        height: 100%;
                        object-fit: cover;
                        /* Ensures the image covers the container without distortion */
                }

                /* Center the subtitle */
                .subtitle {
                        text-align: center;
                        margin-top: 10px;
                }
        </style>
        <!-- End image carousel -->

        <section class="section">
                <div class="container">
                        <div class="has-text-centered">
                                <h1 class="title is-2">Paper List</h1>
                                <p class="subtitle is-4"></p>
                        </div>
                        <div class="content">
                                <div id="type" style="display:none;">Paper List</div>

                                <h2 id="ai-for-scientific-comprehension">1. AI for Scientific Comprehension</h2>


                                <h3 id="table-chart-scientific-comprehension">1.1 Table & Chart Scientific Comprehension
                                </h3>
                                <ul>
                                        <li><i><b>How well do large language models understand tables in materials
                                                                science?</b></i>, Circi et al., <a
                                                        href="https://link.springer.com/article/10.1007/s40192-024-00362-6"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using
                                                                Language Models</b></i>, Newman et al., <a
                                                        href="https://aclanthology.org/2024.emnlp-main.538/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Sciverse: Unveiling the knowledge comprehension and visual reasoning
                                                                of lmms on multi-modal scientific problems</b></i>, Guo
                                                et al., <a href="https://arxiv.org/abs/2503.10627" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="chart-understanding">1.1.1 Chart Understanding</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Chartassisstant: A universal chart multimodal language model via
                                                                chart-to-table pre-training and multitask instruction
                                                                tuning</b></i>, Meng et al., <a
                                                        href="https://arxiv.org/abs/2401.02384" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SPIQA: A Dataset for Multimodal Question Answering on Scientific
                                                                Papers</b></i>, Pramanick et al., <a
                                                        href="https://openreview.net/forum?id=h3lddsY5nf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ChartInstruct: Instruction Tuning for Chart Comprehension and
                                                                Reasoning</b></i>, Masry et al., <a
                                                        href="https://aclanthology.org/2024.findings-acl.619/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ChartAssistant: A Universal Chart Multimodal Language Model via
                                                                Chart-to-Table Pre-training and Multitask Instruction
                                                                Tuning</b></i>, Meng et al., <a
                                                        href="https://aclanthology.org/2024.findings-acl.463/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>SceMQA: A Scientific College Entrance Level Multimodal Question
                                                                Answering Benchmark</b></i>, Liang et al., <a
                                                        href="https://aclanthology.org/2024.acl-short.11/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of
                                                                Large Vision-Language Models</b></i>, Li et al., <a
                                                        href="https://aclanthology.org/2024.acl-long.775/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>SynChart: Synthesizing Charts from Language Models</b></i>, Liu et
                                                al., <a href="https://arxiv.org/abs/2409.16517" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>NovaChart: A Large-scale Dataset towards Chart Understanding and
                                                                Generation of Multimodal Large Language Models</b></i>,
                                                Hu et al., <a href="https://openreview.net/forum?id=PTYL6011vp"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.10-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ChartGemma: Visual Instruction-tuning for Chart Reasoning in the
                                                                Wild</b></i>, Masry et al., <a
                                                        href="https://aclanthology.org/2025.coling-industry.54/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ChartSketcher: Reasoning with Multimodal Feedback and Reflection for
                                                                Chart Understanding</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2505.19076" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports
                                                                From Scratch with Agentic Framework</b></i>, Yang et
                                                al., <a href="https://arxiv.org/abs/2506.02454" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="table-understanding">1.1.2 Table Understanding</h4>
                                </ul>

                                <ul>
                                        <li><i><b>A survey on table-and-text hybridqa: Concepts, methods, challenges and
                                                                future directions</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2212.13465" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Chain-of-Table: Evolving Tables in the Reasoning Chain for Table
                                                                Understanding</b></i>, Wang et al., <a
                                                        href="https://openreview.net/forum?id=4L0xnS4GQM"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Improving demonstration diversity by human-free fusing for
                                                                text-to-SQL</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2402.10663" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Table Meets LLM: Can Large Language Models Understand Structured Table
                                                                Data? A Benchmark and Empirical Study</b></i>, Sui et
                                                al., <a href="https://doi.org/10.1145/3616855.3635752"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Multimodal Table Understanding</b></i>, Zheng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale
                                                                Table Understanding</b></i>, Ji et al., <a
                                                        href="https://arxiv.org/abs/2411.08516" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Tablemaster: A recipe to advance table understanding with language
                                                                models</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2501.19378" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey of table reasoning with large language models</b></i>, Zhang
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The Mighty ToRR: A Benchmark for Table Reasoning and
                                                                Robustness</b></i>, Ashury-Tahan et al., <a
                                                        href="https://arxiv.org/abs/2502.19412" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Tablebench: A comprehensive and complex benchmark for table question
                                                                answering</b></i>, Wu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="textual-scientific-comprehension">1.2 Textual Scientific Comprehension</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Open-retrieval conversational question answering</b></i>, Qu et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2020.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>A non-factoid question-answering taxonomy</b></i>, Bolotova et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>How Well Do Large Language Models Extract Keywords? A Systematic
                                                                Evaluation on Scientific Corpora</b></i>, Mansour et
                                                al., <a href="https://aclanthology.org/2025.aisd-main.2/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <h4 id="full-automatic-scientific-comprehension">1.2.3 Full-Automatic Scientific
                                        Comprehension</h4>
                                </ul>

                                <b>Self-Questioning & Self-Reflection Automatic Scientific Comprehension</b>
                                <ul>
                                        <li><i><b>Large language models can self-improve</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2210.11610" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Selfcheck: Using llms to zero-shot check their own step-by-step
                                                                reasoning</b></i>, Miao et al., <a
                                                        href="https://arxiv.org/abs/2308.00436" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enabling Language Models to Implicitly Learn Self-Improvement</b></i>,
                                                Wang et al., <a href="https://arxiv.org/abs/2310.00898"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciglm: Training scientific language models with self-reflective
                                                                instruction annotation and tuning</b></i>, Zhang et al.,
                                                <a href="https://arxiv.org/abs/2401.07950" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Generating Multiple Choice Questions from Scientific Literature via
                                                                Large Language Models</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>SciQAG: A Framework for Auto-Generated Science Question Answering
                                                                Dataset with Fine-grained Evaluation</b></i>, Wan et
                                                al., <a href="https://arxiv.org/abs/2405.09939" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Recursive introspection: Teaching language model agents how to
                                                                self-improve</b></i>, Qu et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Mind the Gap: Examining the Self-Improvement Capabilities of Large
                                                                Language Models</b></i>, Song et al., <a
                                                        href="https://arxiv.org/abs/2412.02674" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>FRAME: Feedback-Refined Agent Methodology for Enhancing Medical
                                                                Research Insights</b></i>, Yu et al., <a
                                                        href="https://arxiv.org/abs/2505.04649" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Introspective Growth: Automatically Advancing LLM Expertise in
                                                                Technology Judgment</b></i>, Wu et al., <a
                                                        href="https://arxiv.org/abs/2505.12452" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Summarization-guided Automatic Scientific Comprehension</b>
                                <ul>
                                        <li><i><b>Straight from the scientist's mouth—plain language summaries promote
                                                                laypeople's comprehension and knowledge acquisition when
                                                                reading about individual research findings in
                                                                psychology</b></i>, Kerwer et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Hierarchical attention graph for scientific document summarization in
                                                                global and local level</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2405.10202" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can Large Language Model Summarizers Adapt to Diverse Scientific
                                                                Communication Goals?</b></i>, Fonseca et al., <a
                                                        href="https://aclanthology.org/2024.findings-acl.508/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research
                                                                Papers</b></i>, Ifargan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="semi-automatic-scientific-comprehension">1.2.4 Semi-Automatic Scientific
                                        Comprehension</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Scholarchemqa: Unveiling the power of language models in chemical
                                                                research question answering</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2407.16931" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Evaluating and Training Long-Context Large Language Models for
                                                                Question Answering on Scientific Papers</b></i>, Hilgert
                                                et al., <a href="https://aclanthology.org/2024.customnlp4u-1.17/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Are plain language summaries more readable than scientific abstracts?
                                                                Evidence from six biomedical and life sciences
                                                                journals</b></i>, Wen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Human-Guided Scientific Comprehension</b>
                                <ul>
                                        <li><i><b>Clam: Selective clarification for ambiguous questions with generative
                                                                language models</b></i>, Kuhn et al., <a
                                                        href="https://arxiv.org/abs/2212.07769" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Clarify when necessary: Resolving ambiguity through interaction with
                                                                lms</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2311.09469" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Empowering language models with active inquiry for deeper
                                                                understanding</b></i>, Pang et al., <a
                                                        href="https://arxiv.org/abs/2402.03719" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Iqa-eval: Automatic evaluation of human-model interactive question
                                                                answering</b></i>, Li et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via
                                                                agentic tree search</b></i>, Yamada et al., <a
                                                        href="https://arxiv.org/abs/2504.08066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Truly Assessing Fluid Intelligence of Large Language Models through
                                                                Dynamic Reasoning Evaluation</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2506.02648" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Self-guided Scientific Comprehension</b>
                                <ul>
                                        <li><i><b>Boolq: Exploring the surprising difficulty of natural yes/no
                                                                questions</b></i>, Clark et al., <a
                                                        href="https://arxiv.org/abs/1905.10044" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciBERT: A Pretrained Language Model for Scientific Text</b></i>,
                                                Beltagy et al., <a href="https://aclanthology.org/D19-1371/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2019.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>CoQUAD: a COVID-19 question answering dataset system, facilitating
                                                                research, benchmarking, and practice</b></i>, Raza et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Quaser: Question answering with scalable extractive
                                                                rationalization</b></i>, Ghoshal et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Spaceqa: Answering questions about the design of space missions and
                                                                space craft concepts</b></i>, Garcia-Silva et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>What if: Generating code to answer simulation questions in chemistry
                                                                texts</b></i>, Peretz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Biomedlm: A 2.7 b parameter language model trained on biomedical
                                                                text</b></i>, Bolton et al., <a
                                                        href="https://arxiv.org/abs/2403.18421" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scifibench: Benchmarking large multimodal models for scientific figure
                                                                interpretation</b></i>, Roberts et al., <a
                                                        href="https://arxiv.org/abs/2405.08807" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scholarchemqa: Unveiling the power of language models in chemical
                                                                research question answering</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2407.16931" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mmsci: A dataset for graduate-level multi-discipline multimodal
                                                                scientific understanding</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2407.04903" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of
                                                                Large Vision-Language Models</b></i>, Li et al., <a
                                                        href="https://aclanthology.org/2024.acl-long.775/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>What are the essential factors in crafting effective long context
                                                                multi-hop instruction datasets? insights and best
                                                                practices</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2409.01893" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Fine-Tuning Large Language Models for Scientific Text Classification:
                                                                A Comparative Study</b></i>, Rostam et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>L-CiteEval: Do Long-Context Models Truly Leverage Context for
                                                                Responding?</b></i>, Tang et al., <a
                                                        href="https://arxiv.org/abs/2410.02115" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Toward expert-level medical question answering with large language
                                                                models</b></i>, Singhal et al., <img
                                                        src="https://img.shields.io/badge/Nature Medicine-2025-green"
                                                        alt="Nature Medicine Badge"></li>
                                        <li><i><b>A comprehensive survey on long context language modeling</b></i>, Liu
                                                et al., <a href="https://arxiv.org/abs/2503.17407" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey on transformer context extension: Approaches and
                                                                evaluation</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2503.13299" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Tool-Augmented Scientific Comprehension</b>
                                <ul>
                                        <li><i><b>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document
                                                                Understanding</b></i>, Wright et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Scienceqa: A novel resource for question answering on scholarly
                                                                articles</b></i>, Saikh et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Human and technological infrastructures of fact-checking</b></i>,
                                                Juneja et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Paperqa: Retrieval-augmented generative agent for scientific
                                                                research</b></i>, L{\'a}la et al., <a
                                                        href="https://arxiv.org/abs/2312.07559" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Efficacy analysis of online artificial intelligence fact-checking
                                                                tools</b></i>, Hartley et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Language agents achieve superhuman synthesis of scientific
                                                                knowledge</b></i>, Skarlinski et al., <a
                                                        href="https://arxiv.org/abs/2409.13740" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a
                                                                global perspective</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2410.17600" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciAgent: Tool-augmented Language Models for Scientific
                                                                Reasoning</b></i>, Ma et al., <a
                                                        href="https://aclanthology.org/2024.emnlp-main.880/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Hallucination Mitigation using Agentic AI Natural Language-Based
                                                                Frameworks</b></i>, Gosmar et al., <a
                                                        href="https://arxiv.org/abs/2501.13946" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large
                                                                Language Models and Retrieval-Augmented
                                                                Generation</b></i>, Kim et al., <a
                                                        href="https://arxiv.org/abs/2502.03004" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards reasoning era: A survey of long chain-of-thought for reasoning
                                                                large language models</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2503.09567" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Self-Critique Guided Iterative Reasoning for Multi-hop Question
                                                                Answering</b></i>, Chu et al., <a
                                                        href="https://arxiv.org/abs/2505.19112" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal
                                                                Hallucinations Detection in Large Language
                                                                Models</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2505.19108" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>
                                <h2 id="ai-for-academic-survey">2. AI for Academic Survey</h2>
                                <ul>
                                        <li><i><b>Pre-writing: The stage of discovery in the writing process</b></i>,
                                                Rohman et al., <img
                                                        src="https://img.shields.io/badge/Other Source-1965.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="overview-report-generation">2.1 Overview Report Generation</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Towards automated related work summarization</b></i>, Hoang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                </ul>

                                <h4 id="document-level-survey-generation">2.1.1 Document-level Survey Generation</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Analyzing the past to prepare for the future: Writing a literature
                                                                review</b></i>, Webster et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2002.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Hierarchical catalogue generation for literature review: a
                                                                benchmark</b></i>, Zhu et al., <a
                                                        href="https://arxiv.org/abs/2304.03512" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Bio-sieve: exploring instruction tuning large language models for
                                                                systematic review automation</b></i>, Robinson et al.,
                                                <a href="https://arxiv.org/abs/2308.06610" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.08-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Litllm: A toolkit for scientific literature review</b></i>, Agarwal et
                                                al., <a href="https://arxiv.org/abs/2402.01788" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Assisting in writing wikipedia-like articles from scratch with large
                                                                language models</b></i>, Shao et al., <a
                                                        href="https://arxiv.org/abs/2402.14207" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Artificial intelligence for literature reviews: Opportunities and
                                                                challenges</b></i>, Bolanos et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Language agents achieve superhuman synthesis of scientific
                                                                knowledge</b></i>, Skarlinski et al., <a
                                                        href="https://arxiv.org/abs/2409.13740" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Instruct Large Language Models to Generate Scientific Literature
                                                                Survey Step by Step</b></i>, Lai et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Openscholar: Synthesizing scientific literature with
                                                                retrieval-augmented lms</b></i>, Asai et al., <a
                                                        href="https://arxiv.org/abs/2411.14199" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Intelligent summaries: Will Artificial Intelligence mark the finale
                                                                for biomedical literature reviews?</b></i>, Galli et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Autosurvey: Large language models can automatically write
                                                                surveys</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>LAG: LLM agents for Leaderboard Auto Generation on Demanding</b></i>,
                                                Wu et al., <a href="https://arxiv.org/abs/2502.18209"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SurveyX: Academic Survey Automation via Large Language Models</b></i>,
                                                Liang et al., <a href="https://arxiv.org/abs/2502.14776"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automating research synthesis with domain-specific large language
                                                                model fine-tuning</b></i>, Susnjak et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and
                                                                Multi-dimensional Evaluation for Automated Survey
                                                                Writing</b></i>, Yan et al., <a
                                                        href="https://arxiv.org/abs/2503.04629" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="research-roadmap-mapping">2.1.2 Research Roadmap Mapping</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Hierarchical catalogue generation for literature review: a
                                                                benchmark</b></i>, Zhu et al., <a
                                                        href="https://arxiv.org/abs/2304.03512" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Assisting in writing wikipedia-like articles from scratch with large
                                                                language models</b></i>, Shao et al., <a
                                                        href="https://arxiv.org/abs/2402.14207" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Chime: Llm-assisted hierarchical organization of scientific studies
                                                                for literature review support</b></i>, Hsu et al., <a
                                                        href="https://arxiv.org/abs/2407.16148" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Knowledge Navigator: LLM-guided Browsing Framework for Exploratory
                                                                Search in Scientific Literature</b></i>, Katz et al., <a
                                                        href="https://arxiv.org/abs/2408.15836" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Understanding Survey Paper Taxonomy about Large Language Models via
                                                                Graph Representation Learning</b></i>, Zhuang et al., <a
                                                        href="https://aclanthology.org/2024.sdp-1.6/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Artificial intelligence for literature reviews: Opportunities and
                                                                challenges</b></i>, Bolanos et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Taxonomy Tree Generation from Citation Graph</b></i>, Hu et al., <a
                                                        href="https://arxiv.org/abs/2410.03761" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLMs for Literature Review: Are we there yet?</b></i>, Agarwal et al.,
                                                <a href="https://arxiv.org/abs/2412.15249" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Autosurvey: Large language models can automatically write
                                                                surveys</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and
                                                                Multi-dimensional Evaluation for Automated Survey
                                                                Writing</b></i>, Yan et al., <a
                                                        href="https://arxiv.org/abs/2503.04629" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards reasoning era: A survey of long chain-of-thought for reasoning
                                                                large language models</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2503.09567" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Ai2 Scholar QA: Organized Literature Synthesis with
                                                                Attribution</b></i>, Singh et al., <a
                                                        href="https://arxiv.org/abs/2504.10861" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="section-level-related-work-generation">2.1.3 Section-level Related Work
                                        Generation</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Towards automated related work summarization</b></i>, Hoang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Capturing relations between scientific papers: An abstractive model
                                                                for related work section generation</b></i>, Chen et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Target-aware abstractive related work generation with contrastive
                                                                learning</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The use of a large language model to create plain language summaries
                                                                of evidence reviews in healthcare: A feasibility
                                                                study</b></i>, Ovelman et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Related Work and Citation Text Generation: A Survey</b></i>, Li et
                                                al., <a href="https://aclanthology.org/2024.emnlp-main.767/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>376 Using a large language model to create lay summaries of clinical
                                                                study descriptions</b></i>, Kaiser et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Select, Read, and Write: A Multi-Agent Framework of Full-Text-based
                                                                Related Work Generation</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.19647" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Extractive Related Work.</b>
                                <ul>
                                        <li><i><b>Towards automated related work summarization</b></i>, Hoang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Automatic generation of related work sections in scientific papers: an
                                                                optimization approach</b></i>, Hu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2014.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Neural related work summarization with a joint context-driven
                                                                attention mechanism</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/1901.09492" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automatic generation of related work through summarizing
                                                                citations</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Toc-rwg: Explore the combination of topic model and citation
                                                                information for automatic related work
                                                                generation</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Automatic Related Work Section Generation by Sentence Extraction and
                                                                Reordering.</b></i>, Deng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Generative Related Work.</b>
                                <ul>
                                        <li><i><b>Neural related work summarization with a joint context-driven
                                                                attention mechanism</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/1901.09492" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated lay language summarization of biomedical scientific
                                                                reviews</b></i>, Guo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>BACO: A background knowledge-and content-based framework for citing
                                                                sentence generation</b></i>, Ge et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Capturing relations between scientific papers: An abstractive model
                                                                for related work section generation</b></i>, Chen et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Target-aware abstractive related work generation with contrastive
                                                                learning</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Multi-document scientific summarization from a knowledge graph-centric
                                                                view</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2209.04319" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Controllable citation sentence generation with language
                                                                models</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2211.07066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Causal intervention for abstractive related work generation</b></i>,
                                                Liu et al., <a href="https://arxiv.org/abs/2305.13685"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Cited text spans for citation text generation</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2309.06365" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards a unified framework for reference retrieval and related work
                                                                generation</b></i>, Shi et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Explaining relationships among research papers</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2402.13426" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Shallow synthesis of knowledge in gpt-generated texts: A case study in
                                                                automatic related work composition</b></i>, Martin-Boyle
                                                et al., <a href="https://arxiv.org/abs/2402.12255" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Related work and citation text generation: A survey</b></i>, Li et
                                                al., <a href="https://arxiv.org/abs/2404.11588" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document
                                                                Abstractive Summarization</b></i>, Pu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Reinforced Subject-Aware Graph Neural Network for Related Work
                                                                Generation</b></i>, Yu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Disentangling Instructive Information from Ranked Multiple Candidates
                                                                for Multi-Document Scientific Summarization</b></i>,
                                                Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Toward Related Work Generation with Structure and Novelty
                                                                Statement</b></i>, Nishimura et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Estimating Optimal Context Length for Hybrid Retrieval-augmented
                                                                Multi-document Summarization</b></i>, Pratapa et al., <a
                                                        href="https://arxiv.org/abs/2504.12972" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature
                                                                Summarization</b></i>, Achkar et al., <a
                                                        href="https://arxiv.org/abs/2505.16349" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="related-work-retrieval">2.2 Related Work Retrieval</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Paper recommender systems: a literature survey</b></i>, Beel et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2016.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>A Review on Personalized Academic Paper Recommendation.</b></i>, Li et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Insights into relevant knowledge extraction techniques: a
                                                                comprehensive review</b></i>, Shahid et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2020.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A survey on rag meeting llms: Towards retrieval-augmented large
                                                                language models</b></i>, Fan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Graph-Guided Retrieval</b>
                                <ul>
                                        <li><i><b>From who you know to what you read: Augmenting scientific
                                                                recommendations with implicit social networks</b></i>,
                                                Kang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Comlittee: Literature discovery with personal elected author
                                                                committees</b></i>, Kang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Citationsum: Citation-aware graph contrastive learning for scientific
                                                                paper summarization</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Explaining relationships among research papers</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2402.13426" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>KGValidator: A Framework for Automatic Validation of Knowledge Graph
                                                                Construction</b></i>, Boylan et al., <a
                                                        href="https://arxiv.org/abs/2404.15923" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>An academic recommender system on large citation data based on
                                                                clustering, graph modeling and deep learning</b></i>,
                                                Stergiopoulos et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ArZiGo: A recommendation system for scientific articles</b></i>,
                                                Pinedo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a
                                                                global perspective</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2410.17600" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Taxonomy Tree Generation from Citation Graph</b></i>, Hu et al., <a
                                                        href="https://arxiv.org/abs/2410.03761" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Construction and Application of Materials Knowledge Graph in
                                                                Multidisciplinary Materials Science via Large Language
                                                                Model</b></i>, Ye et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Docs2KG: A Human-LLM Collaborative Approach to Unified Knowledge Graph
                                                                Construction from Heterogeneous Documents</b></i>, Sun
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>LLM-Augmented Retrieval</b>
                                <ul>
                                        <li><i><b>Paperweaver: Enriching topical paper alerts by contextualizing
                                                                recommended papers with user-collected papers</b></i>,
                                                Lee et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source
                                                                Question-Answer Systems using Large Language
                                                                Models</b></i>, Seabra et al., <a
                                                        href="https://arxiv.org/abs/2412.17964" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Agentic Retrieval-Augmented Generation: A Survey on Agentic
                                                                RAG</b></i>, Singh et al., <a
                                                        href="https://arxiv.org/abs/2501.09136" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He
                                                et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CuriousLLM: Elevating multi-document question answering with
                                                                llm-enhanced knowledge graph reasoning</b></i>, Yang et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Introducing Deep Research</b></i>, {OpenAI} et al., <a
                                                        href="https://openai.com/index/introducing-deep-research/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.02-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>LitLLMs, LLMs for Literature Review: Are we there yet?</b></i>,
                                                Agarwal et al., <a href="https://openreview.net/forum?id=heeJqQXKg7"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.04-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Select, Read, and Write: A Multi-Agent Framework of Full-Text-based
                                                                Related Work Generation</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.19647" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>GPT-4o Search Preview</b></i>, {OpenAI} et al., <a
                                                        href="https://platform.openai.com/docs/models/gpt-4o-search-preview"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>WebDancer: Towards Autonomous Information Seeking Agency</b></i>, Wu
                                                et al., <a href="https://arxiv.org/abs/2505.22648" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Iterative self-incentivization empowers large language models as
                                                                agentic searchers</b></i>, Shi et al., <a
                                                        href="https://arxiv.org/abs/2505.20128" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports
                                                                From Scratch with Agentic Framework</b></i>, Yang et
                                                al., <a href="https://arxiv.org/abs/2506.02454" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>DeepResearch Bench: A Comprehensive Benchmark for Deep Research
                                                                Agents</b></i>, Du et al., <a
                                                        href="https://arxiv.org/abs/2506.11763" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AcademicBrowse: Benchmarking Academic Browse Ability of LLMs</b></i>,
                                                Zhou et al., <a href="https://arxiv.org/abs/2506.13784"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Semantic-Guided Retrieval</b>
                                <ul>
                                        <li><i><b>Scientific paper recommendation: A survey</b></i>, Bai et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>SPLADE v2: Sparse lexical and expansion model for information
                                                                retrieval</b></i>, Formal et al., <a
                                                        href="https://arxiv.org/abs/2109.10086" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scientific paper recommendation systems: a literature review of recent
                                                                publications</b></i>, Kreutz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Clinical Trial Retrieval via Multi-grained Similarity
                                                                Learning</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Related Work and Citation Text Generation: A Survey</b></i>, Li et
                                                al., <a href="https://aclanthology.org/2024.emnlp-main.767/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>MIR: Methodology Inspiration Retrieval for Scientific Research
                                                                Problems</b></i>, Garikaparthi et al., <a
                                                        href="https://arxiv.org/abs/2506.00249" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>
                                <h2 id="ai-for-scientific-discovery">3. AI for Scientific Discovery</h2>
                                <ul>
                                        <li><i><b>Scientific discovery in the age of artificial intelligence</b></i>,
                                                Wang et al., <img src="https://img.shields.io/badge/Nature-2023-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Beyond Benchmarking: Automated Capability Discovery via Model
                                                                Self-Exploration</b></i>, Lu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AIRUS: a simple workflow for AI-assisted exploration of scientific
                                                                data</b></i>, Harris et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>On the Rise of New Mathematical Spaces and Towards AI-Driven
                                                                Scientific Discovery</b></i>, Raeini et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule
                                                                Learning with Large Language Models</b></i>, He et al.,
                                                <a href="https://arxiv.org/abs/2505.21935" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>AI-Driven Discovery: The Transformative Impact of Machine Learning on
                                                                Research and Development</b></i>, Roy et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="full-automatic-discovery">3.1 Full-Automatic Discovery</h3>
                                </ul>

                                <ul>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Aviary: training language agents on challenging scientific
                                                                tasks</b></i>, Narayanan et al., <a
                                                        href="https://arxiv.org/abs/2412.21154" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking,
                                                                Practice, and Feedback</b></i>, Yuan et al., <a
                                                        href="https://arxiv.org/abs/2501.03916" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autonomous Microscopy Experiments through Large Language Model
                                                                Agents</b></i>, Mandal et al., <a
                                                        href="https://arxiv.org/abs/2501.10385" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Curie: Toward rigorous and automated scientific experimentation with
                                                                ai agents</b></i>, Kon et al., <a
                                                        href="https://arxiv.org/abs/2502.16069" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>DORA AI Scientist: Multi-agent Virtual Research Team for Scientific
                                                                Exploration Discovery and Automated Report
                                                                Generation</b></i>, Naumov et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Carl Technical Report</b></i>, Institute et al., <a
                                                        href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Zochi Technical Report</b></i>, AI et al., <a
                                                        href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>NovelSeek: When Agent Becomes the Scientist--Building Closed-Loop
                                                                System from Hypothesis to Verification</b></i>, Team et
                                                al., <a href="https://arxiv.org/abs/2505.16938" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open
                                                                Co-Scientists</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2506.08140" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>VISION: A modular AI assistant for natural human-instrument
                                                                interaction at scientific user facilities</b></i>,
                                                Mathur et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="idea-mining">3.2 Idea Mining</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Can Large Language Models Unlock Novel Scientific Research
                                                                Ideas?</b></i>, Kumar et al., <a
                                                        href="https://arxiv.org/abs/2409.06185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can llms generate novel research ideas? a large-scale human study with
                                                                100+ nlp researchers</b></i>, Si et al., <a
                                                        href="https://arxiv.org/abs/2409.04109" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLMs can realize combinatorial creativity: generating creative ideas
                                                                via LLMs for scientific research</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2412.14141" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models for causal hypothesis generation in
                                                                science</b></i>, Cohrs et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Futuregen: Llm-rag approach to generate the future work of scientific
                                                                article</b></i>, Azher et al., <a
                                                        href="https://arxiv.org/abs/2503.16561" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via
                                                                Inspiration-Based Task Decomposition</b></i>, Liu et
                                                al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sparks of science: Hypothesis generation using structured paper
                                                                data</b></i>, O'Neill et al., <a
                                                        href="https://arxiv.org/abs/2504.12976" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Spark: A System for Scientifically Creative Idea Generation</b></i>,
                                                Sanyal et al., <a href="https://arxiv.org/abs/2504.20090"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CHIMERA: A Knowledge Base of Idea Recombination in Scientific
                                                                Literature</b></i>, Sternlicht et al., <a
                                                        href="https://arxiv.org/abs/2505.20779" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI
                                                                Knowledge Co-Creation</b></i>, Lin et al., <a
                                                        href="https://arxiv.org/abs/2505.03105" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="idea-mining-from-external-signal">3.2.1 Idea Mining from External Signal</h4>
                                </ul>

                                <b>Idea Mining from External Environment Feedback</b>
                                <ul>
                                        <li><i><b>gpt-researcher</b></i>, Assafelovic et al., <a
                                                        href="https://github.com/assafelovic/gpt-researcher"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Mlagentbench: Evaluating language agents on machine learning
                                                                experimentation</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2310.03302" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Researchagent: Iterative research idea generation over scientific
                                                                literature with large language models</b></i>, Baek et
                                                al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with
                                                                experimental validation</b></i>, Swanson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling
                                                                Discovery of New Ionizable Lipid Designs for mRNA
                                                                Delivery</b></i>, Cui et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a
                                                        href="https://arxiv.org/abs/2502.18864" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Zochi Technical Report</b></i>, AI et al., <a
                                                        href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Carl Technical Report</b></i>, Institute et al., <a
                                                        href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Ideasynth: Iterative research idea development through evolving and
                                                                composing idea facets with literature-grounded
                                                                feedback</b></i>, Pu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Idea Mining from External Knowledge</b>
                                <ul>
                                        <li><i><b>Literature based discovery: models, methods, and trends</b></i>, Henry
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2017.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Predicting the Future of AI with AI: High-quality link prediction in
                                                                an exponentially growing knowledge network</b></i>,
                                                Krenn et al., <a href="https://arxiv.org/abs/2210.00881"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey of large language models</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2303.18223" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models meet nlp: A survey</b></i>, Qin et al., <a
                                                        href="https://arxiv.org/abs/2405.12819" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Position: data-driven discovery with large generative models</b></i>,
                                                Majumder et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Generation and human-expert evaluation of interesting research ideas
                                                                using knowledge graphs and large language
                                                                models</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2405.17044" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Interesting scientific idea generation using knowledge graphs and
                                                                llms: Evaluations with 100 research group
                                                                leaders</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2405.17044" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scimon: Scientific inspiration machines optimized for novelty</b></i>,
                                                Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Accelerating scientific discovery with generative knowledge
                                                                extraction, graph-based representation, and multimodal
                                                                intelligent graph reasoning</b></i>, Buehler et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.09-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Literature meets data: A synergistic approach to hypothesis
                                                                generation</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2410.17309" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Chain of ideas: Revolutionizing research via novel idea development
                                                                with llm agents</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2410.13185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciPIP: An LLM-based Scientific Paper Idea Proposer</b></i>, Wang et
                                                al., <a href="https://arxiv.org/abs/2410.23166" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLMs can realize combinatorial creativity: generating creative ideas
                                                                via LLMs for scientific research</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2412.14141" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Learning to Generate Research Idea with Dynamic Control</b></i>, Li et
                                                al., <a href="https://arxiv.org/abs/2412.14626" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Graph of AI Ideas: Leveraging Knowledge Graphs and LLMs for AI
                                                                Research Idea Generation</b></i>, Gao et al., <a
                                                        href="https://arxiv.org/abs/2503.08549" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sparks of science: Hypothesis generation using structured paper
                                                                data</b></i>, O'Neill et al., <a
                                                        href="https://arxiv.org/abs/2504.12976" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="idea-mining-from-internal-knowledge">3.2.2 Idea Mining from Internal Knowledge
                                </h4>
                                </ul>

                                <ul>
                                        <li><i><b>Ideas are dimes a dozen: Large language models for idea generation in
                                                                innovation</b></i>, Girotra et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Prompting Diverse Ideas: Increasing AI Idea Variance</b></i>, Meincke
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Using Large Language Models for Idea Generation in Innovation</b></i>,
                                                Meincke et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Can llms generate novel research ideas? a large-scale human study with
                                                                100+ nlp researchers</b></i>, Si et al., <a
                                                        href="https://arxiv.org/abs/2409.04109" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can Large Language Models Unlock Novel Scientific Research
                                                                Ideas?</b></i>, Kumar et al., <a
                                                        href="https://arxiv.org/abs/2409.06185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ECM: A Unified Electronic Circuit Model for Explaining the Emergence
                                                                of In-Context Learning and Chain-of-Thought in Large
                                                                Language Model</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2502.03325" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Structuring Scientific Innovation: A Framework for Modeling and
                                                                Discovering Impactful Knowledge Combinations</b></i>,
                                                Chen et al., <a href="https://arxiv.org/abs/2503.18865"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Improving Research Idea Generation Through Data: An Empirical
                                                                Investigation in Social Science</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.21396" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enhance Innovation by Boosting Idea Generation with Large Language
                                                                Models</b></i>, Haarmann et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="idea-mining-from-team-discussion">3.2.3 Idea Mining from Team discussion</h4>
                                </ul>

                                <b>AI-AI Collaboration</b>
                                <ul>
                                        <li><i><b>Large language models for automated open-domain scientific hypotheses
                                                                discovery</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2309.02726" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Exploring collaboration mechanisms for llm agents: A social psychology
                                                                view</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2310.02124" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Acceleron: A tool to accelerate research ideation</b></i>, Nigam et
                                                al., <a href="https://arxiv.org/abs/2403.04382" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Hypothesis generation with large language models</b></i>, Zhou et al.,
                                                <a href="https://arxiv.org/abs/2404.04326" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Researchagent: Iterative research idea generation over scientific
                                                                literature with large language models</b></i>, Baek et
                                                al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Llm and simulation as bilevel optimizers: A new paradigm to advance
                                                                physical scientific discovery</b></i>, Ma et al., <a
                                                        href="https://arxiv.org/abs/2405.09783" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciagents: Automating scientific discovery through multi-agent
                                                                intelligent graph reasoning</b></i>, Ghafarollahi et
                                                al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Two heads are better than one: A multi-agent system has the potential
                                                                to improve scientific idea generation</b></i>, Su et
                                                al., <a href="https://arxiv.org/abs/2410.09403" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Chain of ideas: Revolutionizing research via novel idea development
                                                                with llm agents</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2410.13185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Nova: An iterative planning and search approach to enhance novelty and
                                                                diversity of llm generated ideas</b></i>, Hu et al., <a
                                                        href="https://arxiv.org/abs/2410.14255" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with
                                                                experimental validation</b></i>, Swanson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AIGS: Generating Science from AI-Powered Automated
                                                                Falsification</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2411.11910" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large Language Models for Rediscovering Unseen Chemistry Scientific
                                                                Hypotheses</b></i>, Yang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking,
                                                                Practice, and Feedback</b></i>, Yuan et al., <a
                                                        href="https://arxiv.org/abs/2501.03916" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Multi-Novelty: Improve the Diversity and Novelty of Contents Generated
                                                                by Large Language Models via inference-time Multi-Views
                                                                Brainstorming</b></i>, Lagzian et al., <a
                                                        href="https://arxiv.org/abs/2502.12700" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can Language Models Falsify? Evaluating Algorithmic Reasoning with
                                                                Counterexample Creation</b></i>, Sinha et al., <a
                                                        href="https://arxiv.org/abs/2502.19414" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PiFlow: Principle-aware Scientific Discovery with Multi-Agent
                                                                Collaboration</b></i>, Pu et al., <a
                                                        href="https://arxiv.org/abs/2505.15047" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Human-AI Collaboration</b>
                                <ul>
                                        <li><i><b>An Interactive Co-Pilot for Accelerated Research Ideation</b></i>,
                                                Nigam et al., <a href="https://aclanthology.org/2024.hcinlp-1.6/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.06-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Scideator: Human-LLM Scientific Idea Generation Grounded in
                                                                Research-Paper Facet Recombination</b></i>, Radensky et
                                                al., <a href="https://arxiv.org/abs/2409.14634" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>IRIS: Interactive Research Ideation System for Accelerating Scientific
                                                                Discovery</b></i>, Garikaparthi et al., <a
                                                        href="https://arxiv.org/abs/2504.16728" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Human creativity in the age of llms: Randomized experiments on
                                                                divergent and convergent thinking</b></i>, Kumar et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                </ul>



                                <h3 id="novelty-significance-assessment">3.3 Novelty & Significance Assessment</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Does writing with language models reduce content diversity?</b></i>,
                                                Padmakumar et al., <a href="https://arxiv.org/abs/2309.05196"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Greater variability in judgements of the value of novel ideas</b></i>,
                                                Johnson et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>How AI ideas affect the creativity, diversity, and evolution of human
                                                                ideas: evidence from a large, dynamic
                                                                experiment</b></i>, Ashkinaze et al., <a
                                                        href="https://arxiv.org/abs/2401.13481" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A content-based novelty measure for scholarly publications: A proof of
                                                                concept</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Art or artifice? large language models and the false promise of
                                                                creativity</b></i>, Chakrabarty et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>How ai processing delays foster creativity: Exploring research
                                                                question co-creation with an llm-based agent</b></i>,
                                                Liu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Homogenization effects of large language models on human creative
                                                                ideation</b></i>, Anderson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Shared imagination: Llms hallucinate alike</b></i>, Zhou et al., <a
                                                        href="https://arxiv.org/abs/2407.16604" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can llms generate novel research ideas? a large-scale human study with
                                                                100+ nlp researchers</b></i>, Si et al., <a
                                                        href="https://arxiv.org/abs/2409.04109" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Supporting Assessment of Novelty of Design Problems Using Concept of
                                                                Problem SAPPhIRE</b></i>, Singh et al., <a
                                                        href="https://arxiv.org/abs/2410.18629" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Semi-Supervised Classification With Novelty Detection Using Support
                                                                Vector Machines and Linear Discriminant
                                                                Analysis</b></i>, Dove et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Can AI Examine Novelty of Patents?: Novelty Evaluation Based on the
                                                                Correspondence between Patent Claim and Prior
                                                                Art</b></i>, Ikoma et al., <a
                                                        href="https://arxiv.org/abs/2502.06316" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>How do Humans and Language Models Reason About Creativity? A
                                                                Comparative Analysis</b></i>, Laverghetta Jr et al., <a
                                                        href="https://arxiv.org/abs/2502.03253" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Grapheval: A lightweight graph-based llm framework for idea
                                                                evaluation</b></i>, Feng et al., <a
                                                        href="https://arxiv.org/abs/2503.12600" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SCI-IDEA: Context-Aware Scientific Ideation Using Token and Sentence
                                                                Embeddings</b></i>, Keya et al., <a
                                                        href="https://arxiv.org/abs/2503.19257" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enabling ai scientists to recognize innovation: A domain-agnostic
                                                                algorithm for assessing novelty</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2503.01508" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SC4ANM: Identifying optimal section combinations for automated novelty
                                                                prediction in academic papers</b></i>, Wu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="scientific-experiment-conduction">3.4 Scientific Experiment Conduction</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Toward machine learning optimization of experimental design</b></i>,
                                                Baydin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AI-assisted design of experiments at the frontiers of computation:
                                                                methods and new perspectives</b></i>, Vischia et al., <a
                                                        href="https://arxiv.org/abs/2501.04448" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-Driven Automation Can Become the Foundation of Next-Era Science of
                                                                Science Research</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2505.12039" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>EXP-Bench: Can AI Conduct AI Research Experiments?</b></i>, Kon et
                                                al., <a href="https://arxiv.org/abs/2505.24785" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI Scientists Fail Without Strong Implementation Capability</b></i>,
                                                Zhu et al., <a href="https://arxiv.org/abs/2506.01372"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="experiment-design">3.4.4 Experiment Design</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Sciagents: Automating scientific discovery through multi-agent
                                                                intelligent graph reasoning</b></i>, Ghafarollahi et
                                                al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-assisted design of experiments at the frontiers of computation:
                                                                methods and new perspectives</b></i>, Vischia et al., <a
                                                        href="https://arxiv.org/abs/2501.04448" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling
                                                                Discovery of New Ionizable Lipid Designs for mRNA
                                                                Delivery</b></i>, Cui et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a
                                                        href="https://arxiv.org/abs/2502.18864" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Full-Automatic Experiment Design</b>
                                <ul>
                                        <li><i><b>Researchagent: Iterative research idea generation over scientific
                                                                literature with large language models</b></i>, Baek et
                                                al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Biodiscoveryagent: An ai agent for designing genetic perturbation
                                                                experiments</b></i>, Roohani et al., <a
                                                        href="https://arxiv.org/abs/2405.17631" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with
                                                                experimental validation</b></i>, Swanson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large Language Model Assisted Experiment Design with Generative
                                                                Human-Behavior Agents</b></i>, Liu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Carl Technical Report</b></i>, Institute et al., <a
                                                        href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Zochi Technical Report</b></i>, AI et al., <a
                                                        href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Robin: A multi-agent system for automating scientific
                                                                discovery</b></i>, Ghareeb et al., <a
                                                        href="https://arxiv.org/abs/2505.13400" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Semi-Automatic Experiment Design</b>
                                <ul>
                                        <li><i><b>AI-assisted inverse design of sequence-ordered high intrinsic thermal
                                                                conductivity polymers</b></i>, Huang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Meta-Designing Quantum Experiments with Language Models</b></i>, Arlt
                                                et al., <a href="https://arxiv.org/abs/2406.02470" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The application of artificial intelligence-assisted technology in
                                                                cultural and creative product design</b></i>, Liang et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework
                                                                for Scientific Discovery</b></i>, Craig et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.3/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <h4 id="experiment-management">3.4.5 Experiment Management</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Transforming science labs into automated factories of
                                                                discovery</b></i>, Angelopoulos et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Development of an Automated Workflow for Screening the Assembly and
                                                                Host--Guest Behavior of Metal-Organic Cages Towards
                                                                Accelerated Discovery</b></i>, Basford et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AI Driven Experiment Calibration and Control</b></i>, Britton et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Agents for self-driving laboratories applied to quantum
                                                                computing</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2412.07978" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Intelligent experiments through real-time AI: Fast Data Processing and
                                                                Autonomous Detector Control for sPHENIX and future EIC
                                                                detectors</b></i>, Kvapil et al., <a
                                                        href="https://arxiv.org/abs/2501.04845" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Artificial intelligence meets laboratory automation in discovery and
                                                                synthesis of metal--organic frameworks: A
                                                                review</b></i>, Zhao et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Agents for Change: Artificial Intelligent Workflows for Quantitative
                                                                Clinical Pharmacology and Translational
                                                                Sciences</b></i>, Shahin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Science acceleration and accessibility with self-driving labs</b></i>,
                                                Canty et al., <img
                                                        src="https://img.shields.io/badge/Nature Communications-2025-green"
                                                        alt="Nature Communications Badge"></li>
                                        <li><i><b>Accelerating drug discovery with Artificial: a whole-lab orchestration
                                                                and scheduling system for self-driving labs</b></i>,
                                                Fehlis et al., <a href="https://arxiv.org/abs/2504.00986"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Uncovering Bottlenecks and Optimizing Scientific Lab Workflows with
                                                                Cycle Time Reduction Agents</b></i>, Fehlis et al., <a
                                                        href="https://arxiv.org/abs/2505.21534" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Perspective on Utilizing Foundation Models for Laboratory Automation
                                                                in Materials Research</b></i>, Hatakeyama-Sato et al.,
                                                <a href="https://arxiv.org/abs/2506.12312" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                </ul>

                                <b>Close-Loop Management</b>
                                <ul>
                                        <li><i><b>Functional genomic hypothesis generation and experimentation by a
                                                                robot scientist</b></i>, King et al., <img
                                                        src="https://img.shields.io/badge/Nature-2004-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Self-driving laboratory for accelerated discovery of thin-film
                                                                materials</b></i>, MacLeod et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2020.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Self-driving laboratories for chemistry and materials science</b></i>,
                                                Tom et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Autonomous platform for solution processing of electronic
                                                                polymers</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Nature-2025-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Self-driving laboratory platform for many-objective self-optimisation
                                                                of polymer nanoparticle synthesis with cloud-integrated
                                                                machine learning and orthogonal online
                                                                analytics</b></i>, Knox et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Open-Loop Management</b>
                                <ul>
                                        <li><i><b>The future of self-driving laboratories: from human in the loop
                                                                interactive AI to gamification</b></i>, Hysmith et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.03-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Self-driving labs are the new AI asset</b></i>, {Axios} et al., <a
                                                        href="https://www.axios.com/2024/08/09/ai-self-driving-science-labs-research"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>DeepMind and BioNTech build AI lab assistants for scientific
                                                                research</b></i>, Times} et al., <a
                                                        href="https://www.ft.com/content/64b1bb33-095e-4cc5-a911-50df76fa3d1d"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.10-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Autonomous platform for solution processing of electronic
                                                                polymers</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Nature-2025-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Machine learning-led semi-automated medium optimization reveals salt
                                                                as key for flaviolin production in Pseudomonas
                                                                putida</b></i>, Zournas et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="experimental-analysis">3.4.6 Experimental Analysis</h4>
                                </ul>

                                <b>Automated Evaluation Metrics</b>
                                <ul>
                                        <li><i><b>Eight years of AutoML: categorisation, review and trends</b></i>,
                                                Barbudo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Efficient bayesian learning curve extrapolation using prior-data
                                                                fitted networks</b></i>, Adriaensen et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2023-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Automated machine learning: past, present and future</b></i>, Baratchi
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Exploratory Analysis</b>
                                <ul>
                                        <li><i><b>HeLM: Highlighted Evidence augmented Language Model for Enhanced
                                                                Table-to-Text Generation</b></i>, Bian et al., <a
                                                        href="https://arxiv.org/abs/2311.08896" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Table meets llm: Can large language models understand structured table
                                                                data? a benchmark and empirical study</b></i>, Sui et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Table-LLM-Specialist: Language Model Specialists for Tables using
                                                                Iterative Generator-Validator Fine-tuning</b></i>, Xing
                                                et al., <a href="https://arxiv.org/abs/2410.12164" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLM Based Exploratory Data Analysis Using BigQuery Data
                                                                Canvas</b></i>, Chaudhuri et al., <a
                                                        href="https://medium.com/google-cloud/llm-based-exploratory-data-analysis-using-bigquery-data-canvas-42fbecb9f009"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.10-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Theoretical Consistency Analysis</b>
                                <ul>
                                        <li><i><b>Variable Extraction for Model Recovery in Scientific
                                                                Literature</b></i>, Liu et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.1/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper
                                                                Lineage</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2505.20662" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="experimental-conduction">3.4.7 Experimental Conduction</h4>
                                </ul>

                                <b>Automated Machine Learning Experiment Conduction</b>
                                <ul>
                                        <li><i><b>AIDE: Human-Level Performance on Data Science Competitions</b></i>,
                                                Dominik et al., <a href="https://www.weco.ai/blog/technical-report"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.04-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Automl-gpt: Automatic machine learning with gpt</b></i>, Zhang et al.,
                                                <a href="https://arxiv.org/abs/2305.02499" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Automl in the age of large language models: Current challenges, future
                                                                opportunities and risks</b></i>, Tornede et al., <a
                                                        href="https://arxiv.org/abs/2306.08107" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Opendevin: An open platform for ai software developers as generalist
                                                                agents</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2407.16741" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mlr-copilot: Autonomous machine learning research based on large
                                                                language models agents</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2408.14033" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autokaggle: A multi-agent framework for autonomous data science
                                                                competitions</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2410.20424" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models orchestrating structured reasoning achieve
                                                                kaggle grandmaster level</b></i>, Grosnit et al., <a
                                                        href="https://arxiv.org/abs/2411.03562" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MLRC-Bench: Can Language Agents Solve Machine Learning Research
                                                                Challenges?</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2504.09702" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper
                                                                Lineage</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2505.20662" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Variable Extraction for Model Recovery in Scientific
                                                                Literature</b></i>, Liu et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.1/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AlphaEvolve: A coding agent for scientific and algorithmic
                                                                discovery</b></i>, Novikov et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Real-world Experimental Simulation & Conduction.</b>
                                <ul>
                                        <li><i><b>Large language models can self-improve</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2210.11610" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mlcopilot: Unleashing the power of large language models in solving
                                                                machine learning tasks</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2304.14979" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Training socially aligned language models in simulated human
                                                                society</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2305.16960" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Toolllm: Facilitating large language models to master 16000+
                                                                real-world apis</b></i>, Qin et al., <a
                                                        href="https://arxiv.org/abs/2307.16789" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>An autonomous laboratory for the accelerated synthesis of novel
                                                                materials</b></i>, Szymanski et al., <img
                                                        src="https://img.shields.io/badge/Nature-2023-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Autonomous chemical research with large language models</b></i>, Boiko
                                                et al., <img src="https://img.shields.io/badge/Nature-2023-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Reflexion: Language agents with verbal reinforcement learning</b></i>,
                                                Shinn et al., <img src="https://img.shields.io/badge/NeurIPS-2023-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Toolkengpt: Augmenting frozen language models with massive tools via
                                                                tool embeddings</b></i>, Hao et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2023-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Toolformer: Language models can teach themselves to use tools</b></i>,
                                                Schick et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2023-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>scGPT: toward building a foundation model for single-cell multi-omics
                                                                using generative AI</b></i>, Cui et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Large language model agent for hyper-parameter optimization</b></i>,
                                                Liu et al., <a href="https://arxiv.org/abs/2402.01881"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MechAgents: Large language model multi-agent collaborations can solve
                                                                mechanics problems, generate new data, and integrate
                                                                knowledge</b></i>, Ni et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Researchagent: Iterative research idea generation over scientific
                                                                literature with large language models</b></i>, Baek et
                                                al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated social science: Language models as scientist and
                                                                subjects</b></i>, Manning et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Crispr-gpt: An llm agent for automated design of gene-editing
                                                                experiments</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2404.18021" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Position: LLMs can’t plan, but can help planning in LLM-modulo
                                                                frameworks</b></i>, Kambhampati et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Mlr-copilot: Autonomous machine learning research based on large
                                                                language models agents</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2408.14033" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciagents: Automating scientific discovery through multi-agent
                                                                intelligent graph reasoning</b></i>, Ghafarollahi et
                                                al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Wrong-of-thought: An integrated reasoning framework with
                                                                multi-perspective verification and wrong
                                                                information</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2410.04463" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses
                                                                about Real-World Entities</b></i>, Zabaleta et al., <a
                                                        href="https://arxiv.org/abs/2411.18071" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>An automatic end-to-end chemical synthesis development platform
                                                                powered by large language models</b></i>, Ruan et al.,
                                                <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge">
                                        </li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards LLM-Driven Multi-Agent Pipeline for Drug Discovery:
                                                                Neurodegenerative Diseases Case Study</b></i>, Solovev
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>From Individual to Society: A Survey on Social Simulation Driven by
                                                                Large Language Model-based Agents</b></i>, Mou et al.,
                                                <a href="https://arxiv.org/abs/2412.03563" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>On Evaluating LLMs' Capabilities as Functional Approximators: A
                                                                Bayesian Evaluation Framework</b></i>, Siddiqui et al.,
                                                <a href="https://aclanthology.org/2025.coling-main.388/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.01-blue"
                                                                alt="PDF Badge"></a>
                                        </li>
                                        <li><i><b>PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of
                                                                Psychiatric Assessment Conversational Agents</b></i>,
                                                Lee et al., <a href="https://arxiv.org/abs/2501.01594"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking,
                                                                Practice, and Feedback</b></i>, Yuan et al., <a
                                                        href="https://arxiv.org/abs/2501.03916" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>DLPO: Towards a Robust, Efficient, and Generalizable Prompt
                                                                Optimization Framework from a Deep-Learning
                                                                Perspective</b></i>, Peng et al., <a
                                                        href="https://arxiv.org/abs/2503.13413" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Simulating cooperative prosocial behavior with multi-agent LLMs:
                                                                Evidence and mechanisms for AI agents to inform policy
                                                                decisions</b></i>, Sreedhar et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Reinforcing clinical decision support through multi-agent systems and
                                                                ethical ai governance</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2504.03699" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>OpenFOAMGPT 2.0: end-to-end, trustworthy automation for computational
                                                                fluid dynamics</b></i>, Feng et al., <a
                                                        href="https://arxiv.org/abs/2504.19338" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Researchcodeagent: An llm multi-agent system for automated
                                                                codification of research methodologies</b></i>, Gandhi
                                                et al., <a href="https://arxiv.org/abs/2504.20117" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via
                                                                agentic tree search</b></i>, Yamada et al., <a
                                                        href="https://arxiv.org/abs/2504.08066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MooseAgent: A LLM Based Multi-agent Framework for Automating Moose
                                                                Simulation</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2504.08621" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Owl: Optimized workforce learning for general multi-agent assistance
                                                                in real-world task automation</b></i>, Hu et al., <a
                                                        href="https://arxiv.org/abs/2505.23885" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="pre-experiment-estimation">3.4.8 Pre-Experiment Estimation</h4>
                                </ul>

                                <b>Evaluative Prediction</b>
                                <ul>
                                        <li><i><b>DeepCRE: Transforming Drug R&D via AI-Driven Cross-drug Response
                                                                Evaluation</b></i>, Wu et al., <a
                                                        href="https://arxiv.org/abs/2403.03768" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Physical formula enhanced multi-task learning for pharmacokinetics
                                                                prediction</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2404.10354" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific
                                                                workflows</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2406.06357" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Unimatch: Universal matching from atom to task for few-shot drug
                                                                discovery</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2502.12453" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling
                                                                Discovery of New Ionizable Lipid Designs for mRNA
                                                                Delivery</b></i>, Cui et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Predicting Empirical AI Research Outcomes with Language
                                                                Models</b></i>, Wen et al., <a
                                                        href="https://arxiv.org/abs/2506.00794" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models surpass human experts in predicting neuroscience
                                                                results</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Nature-2025-green"
                                                        alt="Nature Badge"></li>
                                </ul>

                                <b>Exploratory Forecasting</b>
                                <ul>
                                        <li><i><b>Automatic chemical design using a data-driven continuous
                                                                representation of molecules</b></i>,
                                                G{\'o}mez-Bombarelli et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2018.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>MolGAN: An implicit generative model for small molecular
                                                                graphs</b></i>, De Cao et al., <a
                                                        href="https://arxiv.org/abs/1805.11973" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2018.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Google DeepMind's AI Dreamed Up 380,000 New Materials. The Next
                                                                Challenge Is Making Them</b></i>, Barber et al., <a
                                                        href="https://www.wired.com/story/an-ai-dreamed-up-380000-new-materials-the-next-challenge-is-making-them/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific
                                                                workflows</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2406.06357" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with
                                                                experimental validation</b></i>, Swanson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a
                                                        href="https://arxiv.org/abs/2502.18864" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>FlavorDiffusion: Modeling Food-Chemical Interactions with
                                                                Diffusion</b></i>, Seo et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.7/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>MOOSE-Chem3: Toward Experiment-Guided Hypothesis Ranking via Simulated
                                                                Experimental Feedback</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.17873" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="theory-analysis">3.5 Theory Analysis</h3>
                                <h4 id="scientific-claim-formalization">3.5.9 Scientific Claim Formalization</h4>
                                </ul>

                                <ul>
                                        <li><i><b>LF: a foundational higher-order-logic</b></i>, Goodsell et al., <a
                                                        href="https://arxiv.org/abs/2401.11050" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Natural Language Hypotheses in Scientific Papers and How to Tame Them:
                                                                Suggested Steps for Formalizing Complex Scientific
                                                                Claims</b></i>, Heger et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Position: Multimodal Large Language Models Can Significantly Advance
                                                                Scientific Reasoning</b></i>, Yan et al., <a
                                                        href="https://arxiv.org/abs/2502.02871" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciclaimhunt: A large dataset for evidence-based scientific claim
                                                                verification</b></i>, Kumar et al., <a
                                                        href="https://arxiv.org/abs/2502.10003" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards Effective Extraction and Evaluation of Factual Claims</b></i>,
                                                Metropolitansky et al., <a href="https://arxiv.org/abs/2502.10855"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>NSF-SciFy: Mining the NSF Awards Database for Scientific
                                                                Claims</b></i>, Rao et al., <a
                                                        href="https://arxiv.org/abs/2503.08600" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Grammars of Formal Uncertainty: When to Trust LLMs in Automated
                                                                Reasoning Tasks</b></i>, Ganguly et al., <a
                                                        href="https://arxiv.org/abs/2505.20047" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Valsci: an open-source, self-hostable literature review utility for
                                                                automated large-batch scientific claim verification
                                                                using large language models</b></i>, Edelman et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                </ul>

                                <h4 id="scientific-evidence-collection">3.5.10 Scientific Evidence Collection</h4>
                                </ul>

                                <ul>
                                        <li><i><b>MultiVerS: Improving scientific claim verification with weak
                                                                supervision and full-document context</b></i>, Wadden et
                                                al., <a href="https://arxiv.org/abs/2112.01640" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Missing counter-evidence renders NLP fact-checking unrealistic for
                                                                misinformation</b></i>, Glockner et al., <a
                                                        href="https://arxiv.org/abs/2210.13865" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Investigating zero-and few-shot generalization in fact
                                                                verification</b></i>, Pan et al., <a
                                                        href="https://arxiv.org/abs/2309.09444" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Comparing knowledge sources for open-domain scientific claim
                                                                verification</b></i>, Vladika et al., <a
                                                        href="https://arxiv.org/abs/2402.02844" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Understanding Fine-grained Distortions in Reports of Scientific
                                                                Findings</b></i>, W{\"u}hrl et al., <a
                                                        href="https://arxiv.org/abs/2402.12431" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Improving health question answering with reliable and time-aware
                                                                evidence retrieval</b></i>, Vladika et al., <a
                                                        href="https://arxiv.org/abs/2404.08359" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Zero-shot scientific claim verification using LLMs and citation
                                                                text</b></i>, Alvarez et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Grounding fallacies misrepresenting scientific publications in
                                                                evidence</b></i>, Glockner et al., <a
                                                        href="https://arxiv.org/abs/2408.12812" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can foundation models actively gather information in interactive
                                                                environments to test hypotheses?</b></i>, Ke et al., <a
                                                        href="https://arxiv.org/abs/2412.06438" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLM-based Corroborating and Refuting Evidence Retrieval for Scientific
                                                                Claim Verification</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2503.07937" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciClaims: An End-to-End Generative System for Biomedical Claim
                                                                Analysis</b></i>, Ortega et al., <a
                                                        href="https://arxiv.org/abs/2503.18526" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="scientific-verification-analysis">3.5.11 Scientific Verification Analysis</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Proofver: Natural logic theorem proving for fact verification</b></i>,
                                                Krishna et al., <img src="https://img.shields.io/badge/TACL-2022-green"
                                                        alt="TACL Badge"></li>
                                        <li><i><b>The state of human-centered NLP technology for fact-checking</b></i>,
                                                Das et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>aedFaCT: Scientific Fact-Checking Made Easier via Semi-Automatic
                                                                Discovery of Relevant Expert Opinions</b></i>, Altuncu
                                                et al., <a href="https://arxiv.org/abs/2305.07796" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>FactKG: Fact verification via reasoning on knowledge graphs</b></i>,
                                                Kim et al., <a href="https://arxiv.org/abs/2305.06590"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Fact-checking complex claims with program-guided reasoning</b></i>,
                                                Pan et al., <a href="https://arxiv.org/abs/2305.12744"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Prompt to be consistent is better than self-consistent? few-shot and
                                                                zero-shot fact verification with pre-trained language
                                                                models</b></i>, Zeng et al., <a
                                                        href="https://arxiv.org/abs/2306.02569" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Unsupervised Pretraining for Fact Verification by Language Model
                                                                Distillation</b></i>, Bazaga et al., <a
                                                        href="https://arxiv.org/abs/2309.16540" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards llm-based fact verification on news claims with a hierarchical
                                                                step-by-step prompting method</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2310.00305" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Characterizing and Verifying Scientific Claims: Qualitative Causal
                                                                Structure is All You Need</b></i>, Wu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Can Large Language Models Detect Misinformation in Scientific News
                                                                Reporting?</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2402.14268" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>What makes medical claims (un) verifiable? analyzing entity and
                                                                relation properties for fact verification</b></i>,
                                                W{\"u}hrl et al., <a href="https://arxiv.org/abs/2402.01360"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ClaimVer: Explainable claim-level verification and evidence
                                                                attribution of text through knowledge graphs</b></i>,
                                                Dammu et al., <a href="https://arxiv.org/abs/2403.09724"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Generating fact checking explanations</b></i>, Atanasova et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>MAGIC: Multi-Argument Generation with Self-Refinement for Domain
                                                                Generalization in Automatic Fact-Checking</b></i>, Kao
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Robust Claim Verification Through Fact Detection</b></i>, Jafari et
                                                al., <a href="https://arxiv.org/abs/2407.18367" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated justification production for claim veracity in fact
                                                                checking: A survey on architectures and
                                                                approaches</b></i>, Eldifrawi et al., <a
                                                        href="https://arxiv.org/abs/2407.12853" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enhancing natural language inference performance with knowledge graph
                                                                for COVID-19 automated fact-checking in Indonesian
                                                                language</b></i>, Muharram et al., <a
                                                        href="https://arxiv.org/abs/2409.00061" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Augmenting the Veracity and Explanations of Complex Fact Checking via
                                                                Iterative Self-Revision with LLMs</b></i>, Zhang et al.,
                                                <a href="https://arxiv.org/abs/2410.15135" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>DEFAME: Dynamic Evidence-based FAct-checking with Multimodal
                                                                Experts</b></i>, Braun et al., <a
                                                        href="https://arxiv.org/abs/2412.10510" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>TheoremExplainAgent: Towards Video-based Multimodal Explanations for
                                                                LLM Theorem Understanding</b></i>, Ku et al., <a
                                                        href="https://arxiv.org/abs/2502.19400" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Explainable Biomedical Claim Verification with Large Language
                                                                Models</b></i>, Liang et al., <a
                                                        href="https://arxiv.org/abs/2502.21014" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Language Agents Mirror Human Causal Reasoning Biases. How Can We Help
                                                                Them Think Like Scientists?</b></i>, GX-Chen et al., <a
                                                        href="https://arxiv.org/abs/2505.09614" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="theorem-proving">3.5.12 Theorem Proving</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Generative language modeling for automated theorem proving</b></i>,
                                                Polu et al., <a href="https://arxiv.org/abs/2009.03393"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2020.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Draft, sketch, and prove: Guiding formal theorem provers with informal
                                                                proofs</b></i>, Jiang et al., <a
                                                        href="https://arxiv.org/abs/2210.12283" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Hypertree proof search for neural theorem proving</b></i>, Lample et
                                                al., <img src="https://img.shields.io/badge/NeurIPS-2022-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Thor: Wielding hammers to integrate language models and automated
                                                                theorem provers</b></i>, Jiang et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2022-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Decomposing the enigma: Subgoal-based demonstration learning for
                                                                formal theorem proving</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2305.16366" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Dt-solver: Automated theorem proving with dynamic-tree sampling guided
                                                                by proof-level value function</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Lego-prover: Neural theorem proving with growing libraries</b></i>,
                                                Wang et al., <a href="https://arxiv.org/abs/2310.00656"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Baldur: Whole-proof generation and repair with large language
                                                                models</b></i>, First et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Mustard: Mastering uniform synthesis of theorem and proof
                                                                data</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2402.08957" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey on deep learning for theorem proving</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2404.09939" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards large language models as copilots for theorem proving in
                                                                lean</b></i>, Song et al., <a
                                                        href="https://arxiv.org/abs/2404.12534" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Proving theorems recursively</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2405.14414" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Deepseek-prover: Advancing theorem proving in llms through large-scale
                                                                synthetic data</b></i>, Xin et al., <a
                                                        href="https://arxiv.org/abs/2405.14333" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Lean-star: Learning to interleave thinking and proving</b></i>, Lin et
                                                al., <a href="https://arxiv.org/abs/2407.10040" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Data for mathematical copilots: Better ways of presenting proofs for
                                                                machine learning</b></i>, Frieder et al., <a
                                                        href="https://arxiv.org/abs/2412.15184" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Deep Active Learning based Experimental Design to Uncover Synergistic
                                                                Genetic Interactions for Host Targeted
                                                                Therapeutics</b></i>, Zhu et al., <a
                                                        href="https://arxiv.org/abs/2502.01012" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Discovering Symbolic Differential Equations with Symmetry
                                                                Invariants</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2505.12083" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>
                                <h2 id="ai-for-academic-writing">4. AI for Academic Writing</h2>
                                <ul>
                                        <li><i><b>Using artificial intelligence in academic writing and research: An
                                                                essential productivity tool</b></i>, Khalifa et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.03-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Human-LLM Coevolution: Evidence from Academic Writing</b></i>, Geng et
                                                al., <a href="https://arxiv.org/abs/2502.09606" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models penetration in scholarly writing and peer
                                                                review</b></i>, Zhou et al., <a
                                                        href="https://arxiv.org/abs/2502.11193" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>And Plato met ChatGPT: an ethical reflection on the use of chatbots in
                                                                scientific research writing, with a particular focus on
                                                                the social sciences</b></i>, Calderon et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="full-automatic-academic-writing">4.1 Full-Automatic Academic Writing</h3>
                                </ul>

                                <ul>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ScholaWrite: A Dataset of End-to-End Scholarly Writing
                                                                Process</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2502.02904" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Beyond outlining: Heterogeneous recursive planning for adaptive
                                                                long-form writing with language models</b></i>, Xiong et
                                                al., <a href="https://arxiv.org/abs/2503.08275" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>,
                                                Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Zochi Technical Report</b></i>, AI et al., <a
                                                        href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Carl Technical Report</b></i>, Institute et al., <a
                                                        href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via
                                                                agentic tree search</b></i>, Yamada et al., <a
                                                        href="https://arxiv.org/abs/2504.08066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="semi-automatic-academic-writing">4.2 Semi-Automatic Academic Writing</h3>
                                <h4 id="assistance-after-manuscript-completion">4.2.1 Assistance After Manuscript
                                        Completion</h4>
                                </ul>

                                <b>Expression & Logical Revision</b>
                                <ul>
                                        <li><i><b>Learning to split and rephrase from Wikipedia edit history</b></i>,
                                                Botha et al., <a href="https://arxiv.org/abs/1808.09468"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2018.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling
                                                                language and discourse</b></i>, Faruqui et al., <a
                                                        href="https://arxiv.org/abs/1808.09422" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2018.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Diamonds in the rough: Generating fluent sentences from early-stage
                                                                drafts for academic writing assistance</b></i>, Ito et
                                                al., <a href="https://arxiv.org/abs/1910.09180" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Text editing by command</b></i>, Faltings et al., <a
                                                        href="https://arxiv.org/abs/2010.12826" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2020.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Wordcraft: A human-AI collaborative editor for story writing</b></i>,
                                                Coenen et al., <a href="https://arxiv.org/abs/2107.07430"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Machine-in-the-loop rewriting for creative image captioning</b></i>,
                                                Padmakumar et al., <a href="https://arxiv.org/abs/2111.04193"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Read, revise, repeat: A system demonstration for human-in-the-loop
                                                                iterative text revision</b></i>, Du et al., <a
                                                        href="https://arxiv.org/abs/2204.03685" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Coauthor: Designing a human-ai collaborative writing dataset for
                                                                exploring language model capabilities</b></i>, Lee et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Sparks: Inspiration for science writing using language models</b></i>,
                                                Gero et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Techniques for supercharging academic writing with generative
                                                                AI</b></i>, Lin et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Overleafcopilot: Empowering academic writing in overleaf with large
                                                                language models</b></i>, Wen et al., <a
                                                        href="https://arxiv.org/abs/2403.09733" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Augmenting the author: Exploring the potential of AI collaboration in
                                                                academic writing</b></i>, Tu et al., <a
                                                        href="https://arxiv.org/abs/2404.16071" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Step-Back Profiling: Distilling User History for Personalized
                                                                Scientific Writing</b></i>, Tang et al., <a
                                                        href="https://arxiv.org/abs/2406.14275" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Closing the Loop: Learning to Generate Writing Feedback via Language
                                                                Model Simulated Student Revisions</b></i>, Nair et al.,
                                                <a href="https://arxiv.org/abs/2410.08058" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Enhancing Chinese Essay Discourse Logic Evaluation Through Optimized
                                                                Fine-Tuning of Large Language Models</b></i>, Song et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Cocoa: Co-Planning and Co-Execution with AI Agents</b></i>, Feng et
                                                al., <a href="https://arxiv.org/abs/2412.10999" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Prototypical Human-AI Collaboration Behaviors from LLM-Assisted
                                                                Writing in the Wild</b></i>, Mysore et al., <a
                                                        href="https://arxiv.org/abs/2505.16023" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic
                                                                Paper Revision</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2505.11336" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The usage of a transformer based and artificial intelligence driven
                                                                multidimensional feedback system in english writing
                                                                instruction</b></i>, Zheng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research
                                                                Papers</b></i>, Ifargan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Grammar Correction</b>
                                <ul>
                                        <li><i><b>Csed: A chinese semantic error diagnosis corpus</b></i>, Sun et al.,
                                                <a href="https://arxiv.org/abs/2305.05183" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Neural Automated Writing Evaluation with Corrective Feedback</b></i>,
                                                Wang et al., <a href="https://arxiv.org/abs/2402.17613"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical
                                                                Error Correction</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2403.17413" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Improving Grammatical Error Correction via Contextual Data
                                                                Augmentation</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2406.17456" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>How Paperpal Enhances English Writing Quality and Improves
                                                                Productivity for Japanese Academics</b></i>, George et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Transforming hematological research documentation with large language
                                                                models: an approach to scientific writing and data
                                                                analysis</b></i>, Yang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The usage of a transformer based and artificial intelligence driven
                                                                multidimensional feedback system in english writing
                                                                instruction</b></i>, Zheng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="assistance-during-manuscript-preparation">4.2.2 Assistance During Manuscript
                                        Preparation</h4>
                                </ul>

                                <b>Overall Logical Structure Guidance</b>
                                <ul>
                                        <li><i><b>LalaEval: A Holistic Human Evaluation Framework for Domain-Specific
                                                                Large Language Models</b></i>, Sun et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>LLM-Rubric: A Multidimensional, Calibrated Approach to Automated
                                                                Evaluation of Natural Language Texts</b></i>, Hashemi et
                                                al., <a href="https://aclanthology.org/2024.acl-long.745/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Title Formulation and Optimization</b>
                                <ul>
                                        <li><i><b>Personalized Graph-Based Retrieval for Large Language Models</b></i>,
                                                Au et al., <a href="https://arxiv.org/abs/2501.02157"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Generating Accurate and Engaging Research Paper Titles Using NLP
                                                                Techniques</b></i>, Bikku et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>MoDeST: A dataset for Multi Domain Scientific Title
                                                                Generation</b></i>, B{\"o}l{\"u}c{\"u} et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Can pre-trained language models generate titles for research
                                                                papers?</b></i>, Rehman et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="assistance-during-manuscript-writing">4.2.3 Assistance During Manuscript Writing
                                </h4>
                                </ul>

                                <ul>
                                        <li><i><b>Enhancing academic writing skills and motivation: assessing the
                                                                efficacy of ChatGPT in AI-assisted language learning for
                                                                EFL students</b></i>, Song et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Human-AI collaboration patterns in AI-assisted academic
                                                                writing</b></i>, Nguyen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Patterns and Purposes: A Cross-Journal Analysis of AI Tool Usage in
                                                                Academic Writing</b></i>, Xu et al., <a
                                                        href="https://arxiv.org/abs/2502.00632" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Divergent llm adoption and heterogeneous convergence paths in research
                                                                writing</b></i>, Lin et al., <a
                                                        href="https://arxiv.org/abs/2504.13629" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Artificial intelligence-assisted academic writing: recommendations for
                                                                ethical use</b></i>, Cheng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Citation Recommendation & Integration</b>
                                <ul>
                                        <li><i><b>Chronological citation recommendation with time preference</b></i>, Ma
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>When large language models meet citation: A survey</b></i>, Zhang et
                                                al., <a href="https://arxiv.org/abs/2309.09727" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Directed Criteria Citation Recommendation and Ranking Through Link
                                                                Prediction</b></i>, Watson et al., <a
                                                        href="https://arxiv.org/abs/2403.18855" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ILCiteR: Evidence-grounded Interpretable Local Citation
                                                                Recommendation</b></i>, Roy et al., <a
                                                        href="https://arxiv.org/abs/2403.08737" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CiteBART: Learning to Generate Citations for Local Citation
                                                                Recommendation</b></i>, {\c{C}}elik et al., <a
                                                        href="https://arxiv.org/abs/2412.17534" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Benchmark for Evaluation and Analysis of Citation Recommendation
                                                                Models</b></i>, Maharjan et al., <a
                                                        href="https://arxiv.org/abs/2412.07713" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He
                                                et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ScholarCopilot: Training Large Language Models for Academic Writing
                                                                with Accurate Citations</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2504.00824" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>How deep do large language models internalize scientific literature
                                                                and citation practices?</b></i>, Algaba et al., <a
                                                        href="https://arxiv.org/abs/2504.02767" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SCIRGC: Multi-Granularity Citation Recommendation and Citation
                                                                Sentence Preference Alignment</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2505.20103" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards AI-assisted Academic Writing</b></i>, Liebling et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.4/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Drawing Figures and Charts</b>
                                <ul>
                                        <li><i><b>Text2chart: A multi-staged chart generator from natural language
                                                                text</b></i>, Rashid et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ChartReader: A unified framework for chart derendering and
                                                                comprehension without heuristic rules</b></i>, Cheng et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Figgen: Text to scientific figure generation</b></i>, Rodriguez et
                                                al., <a href="https://arxiv.org/abs/2306.00800" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automatikz: Text-guided synthesis of scientific vector graphics with
                                                                tikz</b></i>, Belouadi et al., <a
                                                        href="https://arxiv.org/abs/2310.00367" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scicapenter: Supporting caption composition for scientific figures
                                                                with machine-generated captions and ratings</b></i>, Hsu
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ChartFormer: A large vision language model for converting chart images
                                                                into tactile accessible SVGs</b></i>, Moured et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Figuring out Figures: Using Textual References to Caption Scientific
                                                                Figures</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2407.11008" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AiSciVision: A Framework for Specializing Large Multimodal Models in
                                                                Scientific Image Classification</b></i>, Hogan et al.,
                                                <a href="https://arxiv.org/abs/2410.21480" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>ScImage: How Good Are Multimodal Large Language Models at Scientific
                                                                Text-to-Image Generation?</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2412.02368" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Chartcoder: Advancing multimodal large language model for
                                                                chart-to-code generation</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2501.06598" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Understanding How Paper Writers Use AI-Generated Captions in Figure
                                                                Caption Writing</b></i>, Yin et al., <a
                                                        href="https://arxiv.org/abs/2501.06317" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Multi-LLM Collaborative Caption Generation in Scientific
                                                                Documents</b></i>, Kim et al., <a
                                                        href="https://arxiv.org/abs/2501.02552" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>TikZero: Zero-Shot Text-Guided Graphics Program Synthesis</b></i>,
                                                Belouadi et al., <a href="https://arxiv.org/abs/2503.11509"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enhancing Chart-to-Code Generation in Multimodal Large Language Models
                                                                via Iterative Dual Preference Learning</b></i>, Zhang et
                                                al., <a href="https://arxiv.org/abs/2504.02906" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>StarVector: Generating scalable vector graphics code from images and
                                                                text</b></i>, Rodriguez et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via
                                                                agentic tree search</b></i>, Yamada et al., <a
                                                        href="https://arxiv.org/abs/2504.08066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>How to Create Accurate Scientific Illustrations with AI in
                                                                2025</b></i>, Team et al., <a
                                                        href="https://illustrae.co/blog/how-to-create-accurate-scientific-illustrations-ai"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Formula Transcription</b>
                                <ul>
                                        <li><i><b>Towards Semantic Markup of Mathematical Documents via User
                                                                Interaction</b></i>, Vre{\v{c}}ar et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Automated LaTeX Code Generation from Handwritten Math Expressions
                                                                Using Vision Transformer</b></i>, Sundararaj et al., <a
                                                        href="https://arxiv.org/abs/2412.03853" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LATTE: Improving Latex Recognition for Tables and Formulae with
                                                                Iterative Refinement</b></i>, Jiang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>
                                <h2 id="ai-for-academic-peer-reviewing">5. AI for Academic Peer Reviewing</h2>
                                <ul>
                                        <li><i><b>Can we automate scientific reviewing?</b></i>, Yuan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Reviewergpt? an exploratory study on using large language models for
                                                                paper reviewing</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2306.00622" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Unveiling the sentinels: Assessing ai performance in cybersecurity
                                                                peer review</b></i>, Niu et al., <a
                                                        href="https://arxiv.org/abs/2309.05457" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated scholarly paper review: Concepts, technologies, and
                                                                challenges</b></i>, Lin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>What Can Natural Language Processing Do for Peer Review?</b></i>,
                                                Kuznetsov et al., <a href="https://arxiv.org/abs/2405.06563"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Artificial intelligence to support publishing and peer review: A
                                                                summary and review</b></i>, Kousha et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large language models for automated scholarly paper review: A
                                                                survey</b></i>, Zhuang et al., <a
                                                        href="https://arxiv.org/abs/2501.10326" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Evaluating the predictive capacity of ChatGPT for academic peer review
                                                                outcomes across multiple platforms</b></i>, Thelwall et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A framework for reviewing the results of automated conversion of
                                                                structured organic synthesis procedures from the
                                                                literature</b></i>, Machi et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="in-review">5.1 In-Review</h3>
                                <h4 id="meta-review">5.1.1 Meta-Review</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Summarizing multiple documents with conversational structure for
                                                                meta-review generation</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2305.01498" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Meta-review generation with checklist-guided iterative
                                                                introspection</b></i>, Zeng et al., <a
                                                        href="https://arxiv.org/abs/2305.14647" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>When Reviewers Lock Horn: Finding Disagreement in Scientific Peer
                                                                Reviews</b></i>, Kumar et al., <a
                                                        href="https://arxiv.org/abs/2310.18685" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A sentiment consolidation framework for meta-review
                                                                generation</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2402.18005" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Prompting LLMs to Compose Meta-Review Drafts from Peer-Review
                                                                Narratives of Scholarly Manuscripts</b></i>, Santu et
                                                al., <a href="https://arxiv.org/abs/2402.15589" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards automated meta-review generation via an NLP/ML pipeline in
                                                                different stages of the scholarly peer review
                                                                process</b></i>, Kumar et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Metawriter: Exploring the potential and perils of ai writing support
                                                                in scientific peer review</b></i>, Sun et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>GLIMPSE: Pragmatically Informative Multi-Document Summarization for
                                                                Scholarly Reviews</b></i>, Darrin et al., <a
                                                        href="https://arxiv.org/abs/2406.07359" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PeerArg: Argumentative Peer Review with LLMs</b></i>, Sukpanichnant et
                                                al., <a href="https://arxiv.org/abs/2409.16813" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Bridging Social Psychology and LLM Reasoning: Conflict-Aware
                                                                Meta-Review Generation via Cognitive Alignment</b></i>,
                                                Chen et al., <a href="https://arxiv.org/abs/2503.13879"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLMs as Meta-Reviewers' Assistants: A Case Study</b></i>, Hossain et
                                                al., <a href="https://aclanthology.org/2025.naacl-long.395/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.04-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <h4 id="peer-review">5.1.2 Peer-Review</h4>
                                </ul>

                                <b>Comment Generation</b>
                                <ul>
                                        <li><i><b>Kid-review: knowledge-guided scientific review generation with oracle
                                                                pre-training</b></i>, Yuan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Gpt4 is slightly helpful for peer-review assistance: A pilot
                                                                study</b></i>, Robertson et al., <a
                                                        href="https://arxiv.org/abs/2307.05492" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Marg: Multi-agent review generation for scientific papers</b></i>,
                                                D'Arcy et al., <a href="https://arxiv.org/abs/2401.04259"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Peer review as a multi-turn and long-context dialogue with role-based
                                                                interactions</b></i>, Tan et al., <a
                                                        href="https://arxiv.org/abs/2406.05688" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Agentreview: Exploring peer review dynamics with llm agents</b></i>,
                                                Jin et al., <a href="https://arxiv.org/abs/2406.12708"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can large language models provide useful feedback on research papers?
                                                                A large-scale empirical analysis</b></i>, Liang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Automated Focused Feedback Generation for Scientific Writing
                                                                Assistance</b></i>, Chamoun et al., <a
                                                        href="https://aclanthology.org/2024.findings-acl.580/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>The ai scientist: Towards fully automated open-ended scientific
                                                                discovery</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2408.06292" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SEAGraph: Unveiling the Whole Story of Paper Review Comments</b></i>,
                                                Yu et al., <a href="https://arxiv.org/abs/2412.11939"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via
                                                                agentic tree search</b></i>, Yamada et al., <a
                                                        href="https://arxiv.org/abs/2504.08066" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Score Prediction</b>
                                <ul>
                                        <li><i><b>ALL-IN-ONE: Multi-Task Learning BERT Models for Evaluating Peer
                                                                Assessments.</b></i>, Jia et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The quality assist: A technology-assisted peer review based on
                                                                citation functions to predict the paper quality</b></i>,
                                                Basuki et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Exploiting labeled and unlabeled data via transformer fine-tuning for
                                                                peer-review score prediction</b></i>, Muangkammuen et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>RelevAI-Reviewer: A Benchmark on AI Reviewers for Survey Paper
                                                                Relevance</b></i>, Couto et al., <a
                                                        href="https://arxiv.org/abs/2406.10294" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Unified Generation</b>
                                <ul>
                                        <li><i><b>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP
                                                                Applications</b></i>, Kang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2018.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Peerassist: leveraging on paper-review interactions to predict peer
                                                                review decisions</b></i>, Bharti et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Marg: Multi-agent review generation for scientific papers</b></i>,
                                                D'Arcy et al., <a href="https://arxiv.org/abs/2401.04259"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Peer review as a multi-turn and long-context dialogue with role-based
                                                                interactions</b></i>, Tan et al., <a
                                                        href="https://arxiv.org/abs/2406.05688" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated review generation method based on large language
                                                                models</b></i>, Wu et al., <a
                                                        href="https://arxiv.org/abs/2407.20906" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-Driven review systems: evaluating LLMs in scalable and bias-aware
                                                                academic reviews</b></i>, Tyser et al., <a
                                                        href="https://arxiv.org/abs/2408.10365" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MAMORX: Multi-agent multi-modal scientific review generation with
                                                                external knowledge</b></i>, Taechoyotin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Cycleresearcher: Improving automated research via automated
                                                                review</b></i>, Weng et al., <a
                                                        href="https://arxiv.org/abs/2411.00816" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>OpenReviewer: A Specialized Large Language Model for Generating
                                                                Critical Scientific Paper Reviews</b></i>, Idahl et al.,
                                                <a href="https://arxiv.org/abs/2412.11948" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>The role of large language models in the peer-review process:
                                                                opportunities and challenges for medical journal
                                                                reviewers and editors</b></i>, Lee et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>PiCO: Peer Review in LLMs based on Consistency Optimization</b></i>,
                                                Ning et al., <a href="https://openreview.net/forum?id=sfQ6XpApfS"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM
                                                                Reviews</b></i>, Shin et al., <a
                                                        href="https://arxiv.org/abs/2502.17086" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Revieweval: An evaluation framework for ai-generated reviews</b></i>,
                                                Kirtani et al., <a href="https://arxiv.org/abs/2502.11736"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automatically Evaluating the Paper Reviewing Capability of Large
                                                                Language Models</b></i>, Shin et al., <a
                                                        href="https://arxiv.org/abs/2502.17086" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Deepreview: Improving llm-based paper review with human-like deep
                                                                thinking process</b></i>, Zhu et al., <a
                                                        href="https://arxiv.org/abs/2503.08569" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Reviewagents: Bridging the gap between human and ai-generated paper
                                                                reviews</b></i>, Gao et al., <a
                                                        href="https://arxiv.org/abs/2503.08506" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Reviewing Scientific Papers for Critical Problems With Reasoning LLMs:
                                                                Baseline Approaches and Automatic Evaluation</b></i>,
                                                Zhang et al., <a href="https://arxiv.org/abs/2505.23824"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>REMOR: Automated Peer Review Generation with LLM Reasoning and
                                                                Multi-Objective Reinforcement Learning</b></i>,
                                                Taechoyotin et al., <a href="https://arxiv.org/abs/2505.11718"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>TreeReview: A Dynamic Tree of Questions Framework for Deep and
                                                                Efficient LLM-based Scientific Peer Review</b></i>,
                                                Chang et al., <a href="https://arxiv.org/abs/2506.07642"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PaperEval: A universal, quantitative, and explainable paper evaluation
                                                                method powered by a multi-agent system</b></i>, Huang et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="post-review">5.2 Post-Review</h3>
                                <h4 id="influence-analysis">5.2.3 Influence Analysis</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Popular and/or prestigious? Measures of scholarly esteem</b></i>, Ding
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2011.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Measuring academic influence: Not all citations are equal</b></i>, Zhu
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2015.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>An overview of microsoft academic service (mas) and
                                                                applications</b></i>, Sinha et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2015.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Factors affecting number of citations: a comprehensive review of the
                                                                literature</b></i>, Tahamtan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2016.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Relative citation ratio (RCR): a new metric that uses citation rates
                                                                to measure influence at the article level</b></i>,
                                                Hutchins et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2016.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific
                                                                Citation Prediction</b></i>, Hao et al., <a
                                                        href="https://arxiv.org/abs/2410.09112" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>From Words to Worth: Newborn Article Impact Prediction with
                                                                LLM</b></i>, Zhao et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large language models surpass human experts in predicting neuroscience
                                                                results</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Nature-2025-green"
                                                        alt="Nature Badge"></li>
                                </ul>

                                <h4 id="promotion-enhancement">5.2.4 Promotion Enhancement</h4>
                                </ul>

                                <ul>
                                        <li><i><b>From complexity to clarity: How AI enhances perceptions of scientists
                                                                and the public's understanding of science</b></i>,
                                                Markowitz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Automatic Evaluation Metrics for Artificially Generated Scientific
                                                                Research</b></i>, H{\"o}pner et al., <a
                                                        href="https://arxiv.org/abs/2503.05712" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with
                                                                Iterative Feedback Loop for Improved Scientific
                                                                Short-form Generation</b></i>, Park et al., <a
                                                        href="https://arxiv.org/abs/2504.18805" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>P2P: Automated Paper-to-Poster Generation and Fine-Grained
                                                                Benchmark</b></i>, Sun et al., <a
                                                        href="https://arxiv.org/abs/2505.17104" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="pre-review">5.3 Pre-Review</h3>
                                <h4 id="desk-review">5.3.5 Desk-Review</h4>
                                </ul>

                                <ul>
                                        <li><i><b>How to Make Peer Review Recommendations and Decisions</b></i>, Society
                                                et al., <a
                                                        href="https://www.computer.org/publications/making-peer-review-recommendations"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/Other Source-.00-lightgrey"
                                                                alt="Other Source Badge"></a></li>
                                        <li><i><b>Helping editors find reviewers</b></i>, Tedford et al., <a
                                                        href="https://www.elsevier.com/connect/helping-editors-find-reviewers"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/Other Source-2015.09-lightgrey"
                                                                alt="Other Source Badge"></a></li>
                                        <li><i><b>Snapp: Springer Nature's next-generation peer review system</b></i>,
                                                Nature et al., <a href="https://www.springernature.com/gp/snapp"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/Other Source-2023.12-lightgrey"
                                                                alt="Other Source Badge"></a></li>
                                        <li><i><b>Matching papers and reviewers at large conferences</b></i>,
                                                Leyton-Brown et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Streamlining the review process: AI-generated annotations in research
                                                                manuscripts</b></i>, D{\'\i}az et al., <a
                                                        href="https://arxiv.org/abs/2412.00281" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Artificial intelligence in peer review: enhancing efficiency while
                                                                preserving integrity</b></i>, Doskaliuk et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Enhancing Academic Decision-Making: A Pilot Study of AI-Supported
                                                                Journal Selection in Higher Education</b></i>, Farber et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="reviewer-matching">5.3.6 Reviewer Matching</h4>
                                </ul>

                                <ul>
                                        <li><i><b>A framework for optimizing paper matching</b></i>, Charlin et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2011.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>The Toronto paper matching system: an automated paper-reviewer
                                                                assignment system</b></i>, Charlin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2013.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Pistis: A conflict of interest declaration and detection system for
                                                                peer review management</b></i>, Wu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2018.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>An automated conflict of interest based greedy approach for conference
                                                                paper assignment system</b></i>, Pradhan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2020.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Matching papers and reviewers at large conferences</b></i>,
                                                Leyton-Brown et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Autonomous Machine Learning-Based Peer Reviewer Selection
                                                                System</b></i>, Aitymbetov et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Automated Research Review Support Using Machine Learning, Large
                                                                Language Models, and Natural Language
                                                                Processing</b></i>, Pendyala et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Peer review expert group recommendation: A multi-subject
                                                                coverage-based approach</b></i>, Fu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>
                                <h2 id="application-of-ai-for-research">6. Application of AI for Research</h2>


                                <h3 id="ai-for-applied-science-and-engineering-research">6.1 AI for Applied Science and
                                        Engineering Research</h3>
                                <h4 id="ai-for-robotics-and-control-research">6.1.1 AI for Robotics and Control Research
                                </h4>
                                <ul>
                                        <li><i><b>The AI CUDA engineer: Agentic CUDA kernel discovery, optimization and
                                                                composition</b></i>, Lange et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Generative Machine Learning in Adaptive Control of Dynamic
                                                                Manufacturing Processes: A Review</b></i>, Lee et al.,
                                                <a href="https://arxiv.org/abs/2505.00210" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                </ul>

                                <b>Autonomous Design & Optimization</b>
                                <ul>
                                        <li><i><b>Towards industry-ready additive manufacturing: AI-enabled closed-loop
                                                                control for 3D melt electrowriting</b></i>, Mieszczanek
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Closed-loop transfer enables artificial intelligence to yield chemical
                                                                knowledge</b></i>, Angello et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Closed-Loop Visuomotor Control with Generative Expectation for Robotic
                                                                Manipulation</b></i>, Bu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Real-time experiment-theory closed-loop interaction for autonomous
                                                                materials science</b></i>, Liang et al., <a
                                                        href="https://arxiv.org/abs/2410.17430" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-Driven Robotics for Free-Space Optics</b></i>, Uddin et al., <a
                                                        href="https://arxiv.org/abs/2505.17985" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>End-to-End Vision-Based Control</b>
                                <ul>
                                        <li><i><b>End-to-end training of deep visuomotor policies</b></i>, Levine et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2016.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Domain randomization for transferring deep neural networks from
                                                                simulation to the real world</b></i>, Tobin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2017.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Learning hand-eye coordination for robotic grasping with deep learning
                                                                and large-scale data collection</b></i>, Levine et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2018.06-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Scalable deep reinforcement learning for vision-based robotic
                                                                manipulation</b></i>, Kalashnikov et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2018.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Multi-Task & Multi-Agent Control Frameworks</b>
                                <ul>
                                        <li><i><b>Value Iteration for Learning Concurrently Executable Robotic Control
                                                                Tasks</b></i>, Tahmid et al., <a
                                                        href="https://arxiv.org/abs/2504.01174" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>NovelSeek: When Agent Becomes the Scientist--Building Closed-Loop
                                                                System from Hypothesis to Verification</b></i>, Team et
                                                al., <a href="https://arxiv.org/abs/2505.16938" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Sim-to-Real Robustness & Safety</b>
                                <ul>
                                        <li><i><b>Real-world humanoid locomotion with reinforcement learning</b></i>,
                                                Radosavovic et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Improving generalization of robot locomotion policies via
                                                                Sharpness-Aware Reinforcement Learning</b></i>, Bochem
                                                et al., <a href="https://arxiv.org/abs/2411.19732" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Robustness Evaluation of Offline Reinforcement Learning for Robot
                                                                Control Against Action Perturbations</b></i>, Ayabe et
                                                al., <a href="https://arxiv.org/abs/2412.18781" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Zero-shot Sim-to-Real Transfer for Reinforcement Learning-based Visual
                                                                Servoing of Soft Continuum Arms</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2504.16916" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Guided by Guardrails: Control Barrier Functions as Safety Instructors
                                                                for Robotic Learning</b></i>, Guerrier et al., <a
                                                        href="https://arxiv.org/abs/2505.18858" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="ai-for-software-engineering">6.1.2 AI for Software Engineering</h4>
                                </ul>

                                <b>Code Generation</b>
                                <ul>
                                        <li><i><b>Evaluating large language models trained on code</b></i>, Chen et al.,
                                                <a href="https://arxiv.org/abs/2107.03374" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.07-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Codegen: An open large language model for code with multi-turn program
                                                                synthesis</b></i>, Nijkamp et al., <a
                                                        href="https://arxiv.org/abs/2203.13474" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Starcoder: may the source be with you!</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2305.06161" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Code llama: Open foundation models for code</b></i>, Roziere et al.,
                                                <a href="https://arxiv.org/abs/2308.12950" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.08-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>DeepSeek-Coder: When the Large Language Model Meets Programming--The
                                                                Rise of Code Intelligence</b></i>, Guo et al., <a
                                                        href="https://arxiv.org/abs/2401.14196" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Starcoder 2 and the stack v2: The next generation</b></i>, Lozhkov et
                                                al., <a href="https://arxiv.org/abs/2402.19173" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library
                                                                Scenarios</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2506.13824" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Seed-Coder: Let the Code Model Curate Data for Itself</b></i>, Zhang
                                                et al., <a href="https://arxiv.org/abs/2506.03524" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>End-to-End Software Development</b>
                                <ul>
                                        <li><i><b>Application of large language models to software engineering tasks:
                                                                Opportunities, risks, and implications</b></i>, Ozkaya
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Chatdev: Communicative agents for software development</b></i>, Qian
                                                et al., <a href="https://arxiv.org/abs/2307.07924" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language models for software engineering: Survey and open
                                                                problems</b></i>, Fan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Experiential co-learning of software-developing agents</b></i>, Qian
                                                et al., <a href="https://arxiv.org/abs/2312.17025" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Repoexec: Evaluate code generation with a repository-level executable
                                                                benchmark</b></i>, Le Hai et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>SWE-bench: Can Language Models Resolve Real-world Github
                                                                Issues?</b></i>, Jimenez et al., <a
                                                        href="https://openreview.net/forum?id=VTF8yNQM66"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Hyperagent: Generalist software engineering agents to solve coding
                                                                tasks at scale</b></i>, Phan et al., <a
                                                        href="https://arxiv.org/abs/2409.16299" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Explainable automated debugging via large language model-driven
                                                                scientific debugging</b></i>, Kang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="ai-for-natural-science-research">6.2 AI for Natural Science Research</h3>
                                <h4 id="ai-for-biology-medical-research">6.2.3 AI for Biology & Medical Research</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v
                                                                for multimodal medical diagnosis</b></i>, Wu et al., <a
                                                        href="https://arxiv.org/abs/2310.09909" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Advancing multimodal medical capabilities of Gemini</b></i>, Yang et
                                                al., <a href="https://arxiv.org/abs/2405.03162" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey of generative AI for de novo drug design: new frontiers in
                                                                molecule and protein generation</b></i>, Tang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Large language models in plant biology</b></i>, Lam et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with
                                                                experimental validation</b></i>, Swanson et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A Fuzzy Logic-Based Approach to Predict Human Interaction by
                                                                Functional Near-Infrared Spectroscopy</b></i>, Jiang et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Human-AI Teaming Using Large Language Models: Boosting Brain-Computer
                                                                Interfacing (BCI) and Brain Research</b></i>, Kapitonova
                                                et al., <a href="https://arxiv.org/abs/2501.01451" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>From large language models to multimodal AI: A scoping review on the
                                                                potential of generative AI in medicine</b></i>, Buess et
                                                al., <a href="https://arxiv.org/abs/2502.09242" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A survey of llm-based agents in medicine: How far are we from
                                                                baymax?</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2502.11211" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large language model for knowledge synthesis and AI-enhanced
                                                                biomanufacturing</b></i>, Li et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Advancing drug discovery and development through GPT models: a review
                                                                on challenges, innovations and future prospects</b></i>,
                                                Othman et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large Language Models for Zero-shot Inference of Causal Structures in
                                                                Biology</b></i>, Newsham et al., <a
                                                        href="https://arxiv.org/abs/2503.04347" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Transforming hematological research documentation with large language
                                                                models: an approach to scientific writing and data
                                                                analysis</b></i>, Yang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>SpatialAgent: An autonomous AI agent for spatial biology</b></i>, Wang
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework
                                                                for Scientific Discovery</b></i>, Craig et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.3/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>AI-assisted Drug Re-purposing for Human Liver Fibrosis</b></i>, Guan
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Biomni: A General-Purpose Biomedical AI Agent</b></i>, Huang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research
                                                                Papers</b></i>, Ifargan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Cell & Gene Modeling.</b>
                                <ul>
                                        <li><i><b>GenePT: a simple but effective foundation model for genes and cells
                                                                built from ChatGPT</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Biodiscoveryagent: An ai agent for designing genetic perturbation
                                                                experiments</b></i>, Roohani et al., <a
                                                        href="https://arxiv.org/abs/2405.17631" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Cellagent: An llm-driven multi-agent framework for automated
                                                                single-cell data analysis</b></i>, Xiao et al., <a
                                                        href="https://arxiv.org/abs/2407.09811" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Toward a foundation model of causal cell and tissue biology with a
                                                                Perturbation Cell and Tissue Atlas</b></i>, Rood et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>General-purpose pre-trained large cellular models for single-cell
                                                                transcriptomics</b></i>, Bian et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ML-GAP: machine learning-enhanced genomic analysis pipeline using
                                                                autoencoders and data augmentation</b></i>, Agraz et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>LLM4GRN: Discovering Causal Gene Regulatory Networks with
                                                                LLMs--Evaluation through Synthetic Data
                                                                Generation</b></i>, Afonja et al., <a
                                                        href="https://arxiv.org/abs/2410.15828" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autonomous Robotic System with Optical Coherence Tomography Guidance
                                                                for Vascular Anastomosis</b></i>, Haworth et al., <a
                                                        href="https://arxiv.org/abs/2410.07493" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>How to build the virtual cell with artificial intelligence: Priorities
                                                                and opportunities</b></i>, Bunne et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Efficient Fine-Tuning of Single-Cell Foundation Models Enables
                                                                Zero-Shot Molecular Perturbation Prediction</b></i>,
                                                Maleki et al., <a href="https://arxiv.org/abs/2412.13478"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>NeuroDISK: An AI Approach to Automate Continuous Inquiry-Driven
                                                                Discoveries in Neuroimaging Genetics</b></i>, Garijo et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The rise of agentic AI teammates in medicine</b></i>, Zou et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Transformers and genome language models</b></i>, Consens et al., <img
                                                        src="https://img.shields.io/badge/Nature-2025-green"
                                                        alt="Nature Badge"></li>
                                </ul>

                                <b>Clinical Diagnosis</b>
                                <ul>
                                        <li><i><b>Large language models encode clinical knowledge</b></i>, Singhal et
                                                al., <a href="https://doi.org/10.1038/s41586-023-06291-2"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v
                                                                for multimodal medical diagnosis</b></i>, Wu et al., <a
                                                        href="https://arxiv.org/abs/2310.09909" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Advancing clinical decision support: The role of artificial
                                                                intelligence across six domains</b></i>, Khalifa et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Ai hospital: Benchmarking large language models in a multi-agent
                                                                medical interaction simulator</b></i>, Fan et al., <a
                                                        href="https://arxiv.org/abs/2402.09742" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Agent hospital: A simulacrum of hospital with evolvable medical
                                                                agents</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2405.02957" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autonomous Robotic System with Optical Coherence Tomography Guidance
                                                                for Vascular Anastomosis</b></i>, Haworth et al., <a
                                                        href="https://arxiv.org/abs/2410.07493" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Piors: Personalized intelligent outpatient reception based on large
                                                                language model with multi-agents medical scenario
                                                                simulation</b></i>, Bao et al., <a
                                                        href="https://arxiv.org/abs/2411.13902" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a
                                                        href="https://arxiv.org/abs/2502.18864" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Generative Artificial Intelligence in Anatomic Pathology</b></i>,
                                                Brodsky et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Clinicalgpt-r1: Pushing reasoning capability of generalist disease
                                                                diagnosis with large language model</b></i>, Lan et al.,
                                                <a href="https://arxiv.org/abs/2504.09421" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework
                                                                for Scientific Discovery</b></i>, Craig et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.3/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient
                                                                Interactions</b></i>, Kyung et al., <a
                                                        href="https://arxiv.org/abs/2505.17818" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MedSyn: Enhancing Diagnostics with Human-AI Collaboration</b></i>,
                                                Sayin et al., <a href="https://arxiv.org/abs/2506.14774"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Drug Discovery</b>
                                <ul>
                                        <li><i><b>A deep learning approach to antibiotic discovery</b></i>, Stokes et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2020.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Artificial intelligence to deep learning: machine intelligence
                                                                approach for drug discovery</b></i>, Gupta et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>HGTDR: Advancing drug repurposing with heterogeneous graph
                                                                transformers</b></i>, Gharizadeh et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A survey of generative AI for de novo drug design: new frontiers in
                                                                molecule and protein generation</b></i>, Tang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>A data science roadmap for open science organizations engaged in
                                                                early-stage drug discovery</b></i>, Edfeldt et al., <img
                                                        src="https://img.shields.io/badge/Nature Communications-2024-green"
                                                        alt="Nature Communications Badge"></li>
                                        <li><i><b>Drugclip: Contrastive drug-disease interaction for drug
                                                                repurposing</b></i>, Lu et al., <a
                                                        href="https://arxiv.org/abs/2407.02265" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Current strategies to address data scarcity in artificial
                                                                intelligence-based drug discovery: A comprehensive
                                                                review</b></i>, Gangwal et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A foundation model for clinician-centered drug repurposing</b></i>,
                                                Huang et al., <img
                                                        src="https://img.shields.io/badge/Nature Medicine-2024-green"
                                                        alt="Nature Medicine Badge"></li>
                                        <li><i><b>Drugagent: Automating ai-aided drug discovery programming through llm
                                                                multi-agent collaboration</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2411.15692" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards LLM-Driven Multi-Agent Pipeline for Drug Discovery:
                                                                Neurodegenerative Diseases Case Study</b></i>, Solovev
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A Deep Subgrouping Framework for Precision Drug Repurposing via
                                                                Emulating Clinical Trials on Real-world Patient
                                                                Data</b></i>, Lee et al., <a
                                                        href="https://arxiv.org/abs/2412.20373" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Hallucinations Can Improve Large Language Models in Drug
                                                                Discovery</b></i>, Yuan et al., <a
                                                        href="https://arxiv.org/abs/2501.13824" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>RAG-Enhanced Collaborative LLM Agents for Drug Discovery</b></i>, Lee
                                                et al., <a href="https://arxiv.org/abs/2502.17506" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling
                                                                Discovery of New Ionizable Lipid Designs for mRNA
                                                                Delivery</b></i>, Cui et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Advancing drug discovery and development through GPT models: a review
                                                                on challenges, innovations and future prospects</b></i>,
                                                Othman et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>DrugPilot: LLM-based Parameterized Reasoning Agent for Drug
                                                                Discovery</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2505.13940" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-assisted Drug Re-purposing for Human Liver Fibrosis</b></i>, Guan
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Protein Discovery.</b>
                                <ul>
                                        <li><i><b>Improved protein structure prediction using potentials from deep
                                                                learning</b></i>, Senior et al., <img
                                                        src="https://img.shields.io/badge/Nature-2020-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Highly accurate protein structure prediction with AlphaFold</b></i>,
                                                Jumper et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Leveraging biomolecule and natural language through multi-modal
                                                                learning: A survey</b></i>, Pei et al., <a
                                                        href="https://arxiv.org/abs/2403.01528" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ProtAgents: protein discovery via large language model multi-agent
                                                                collaborations combining physics and machine
                                                                learning</b></i>, Ghafarollahi et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Accurate structure prediction of biomolecular interactions with
                                                                AlphaFold 3</b></i>, Abramson et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Automating exploratory proteomics research via language
                                                                models</b></i>, Ding et al., <a
                                                        href="https://arxiv.org/abs/2411.03743" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein
                                                                Design Principles</b></i>, Ghafarollahi et al., <a
                                                        href="https://arxiv.org/abs/2504.19017" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enhancing Chemical Reaction and Retrosynthesis Prediction with Large
                                                                Language Model and Dual-task Learning</b></i>, Lin et
                                                al., <a href="https://arxiv.org/abs/2505.02639" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="ai-for-chemistry&-materials-research">6.2.4 AI for Chemistry& Materials Research
                                </h4>
                                </ul>

                                <ul>
                                        <li><i><b>Accelerating materials discovery using artificial intelligence, high
                                                                performance computing and robotics</b></i>, Pyzer-Knapp
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Accelerating materials language processing with large language
                                                                models</b></i>, Choi et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran
                                                et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Nano & AI: A Nobel Partnership</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Simulating 500 million years of evolution with a language
                                                                model</b></i>, Hayes et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AI4Materials: Transforming the Landscape of Materials Science and
                                                                Enigneering</b></i>, Jiang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Cross-disciplinary perspectives on the potential for artificial
                                                                intelligence across chemistry</b></i>, Mroz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Empowering Generalist Material Intelligence with Large Language
                                                                Models</b></i>, Yuan et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>From Literature to Lab: Hardware-Independent Autonomous Chemical
                                                                Synthesis with Reinforcement Learning</b></i>, Wu et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Automatic Analysis</b>
                                <ul>
                                        <li><i><b>Graph networks as a universal machine learning framework for molecules
                                                                and crystals</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>An autonomous laboratory for the accelerated synthesis of novel
                                                                materials</b></i>, Szymanski et al., <img
                                                        src="https://img.shields.io/badge/Nature-2023-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Accelerating the Discovery of Abiotic Vesicles with AI-Guided
                                                                Automated Experimentation</b></i>, Ekosso et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Sequential closed-loop Bayesian optimization as a guide for organic
                                                                molecular metallophotocatalyst formulation
                                                                discovery</b></i>, Li et al., <img
                                                        src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>High-throughput robotic collection, imaging, and machine learning
                                                                analysis of salt patterns: composition and concentration
                                                                from dried droplet photos</b></i>, Batista et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Adaptive representation of molecules and materials in Bayesian
                                                                optimization</b></i>, Rajabi-Kochi et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>FlavorDiffusion: Modeling Food-Chemical Interactions with
                                                                Diffusion</b></i>, Seo et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.7/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Automatic Discovery</b>
                                <ul>
                                        <li><i><b>Chatgpt-Assisted Rational Design for Iterative Performance
                                                                Optimization of Perovskite Solar Cells</b></i>, Zhang et
                                                al., <img src="https://img.shields.io/badge/Other Source-.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Machine learning for molecular and materials science</b></i>, Butler
                                                et al., <img src="https://img.shields.io/badge/Nature-2018-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Scaling deep learning for materials discovery</b></i>, Merchant et
                                                al., <img src="https://img.shields.io/badge/Nature-2023-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Experimental discovery of novel ammonia synthesis catalysts via active
                                                                learning</b></i>, Jayarathna et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A sober look at LLMs for material discovery: Are they actually good
                                                                for Bayesian optimization over molecules?</b></i>,
                                                Kristiadi et al., <a href="https://arxiv.org/abs/2402.05015"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>BatGPT-Chem: A Foundation Large Model For Chemical
                                                                Engineering</b></i>, Yang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AI-assisted inverse design of sequence-ordered high intrinsic thermal
                                                                conductivity polymers</b></i>, Huang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Real-time experiment-theory closed-loop interaction for autonomous
                                                                materials science</b></i>, Liang et al., <a
                                                        href="https://arxiv.org/abs/2410.17430" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autonomous mobile robots for exploratory synthetic chemistry</b></i>,
                                                Dai et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>Machine Learning-Aided Inverse Design and Discovery of Novel Polymeric
                                                                Materials for Membrane Separation</b></i>, Dangayach et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ORGANA: a robotic assistant for automated chemistry experimentation
                                                                and characterization</b></i>, Darvish et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Adaptive AI decision interface for autonomous electronic material
                                                                discovery</b></i>, Dai et al., <a
                                                        href="https://arxiv.org/abs/2504.13344" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Full Human-AI Collaboration Process Management</b>
                                <ul>
                                        <li><i><b>Automated synthesis of oxygen-producing catalysts from Martian
                                                                meteorites by a robotic AI chemist</b></i>, Zhu et al.,
                                                <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge">
                                        </li>
                                        <li><i><b>ChemReasoner: Heuristic search over a large language model's knowledge
                                                                space using quantum-chemical feedback</b></i>, Sprueill
                                                et al., <a href="https://arxiv.org/abs/2402.10980" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Efficient evolutionary search over chemical space with large language
                                                                models</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2406.16976" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of
                                                                Human-Machine Collaboration</b></i>, Ni et al., <a
                                                        href="https://arxiv.org/abs/2411.08063" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autonomous Microscopy Experiments through Large Language Model
                                                                Agents</b></i>, Mandal et al., <a
                                                        href="https://arxiv.org/abs/2501.10385" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Automated Retrosynthesis Planning of Macromolecules Using Large
                                                                Language Models and Knowledge Graphs</b></i>, Ma et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>A multiagent-driven robotic ai chemist enabling autonomous chemical
                                                                research on demand</b></i>, Song et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Agentic Assistant for Material Scientists</b></i>, Feng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Physics-informed, dual-objective optimization of high-entropy-alloy
                                                                nanozymes by a robotic AI chemist</b></i>, Luo et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Intelligent, Personalized Scientific Assistant via Large Language
                                                                Models for Solid-State Battery Research</b></i>, Leng et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Prim: Principle-inspired material discovery through multi-agent
                                                                collaboration</b></i>, Lai et al., <a
                                                        href="https://arxiv.org/abs/2504.08810" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <h4 id="ai-for-physics-research">6.2.5 AI for Physics Research</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Colloquium: Machine learning in nuclear physics</b></i>, Boehnlein et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Toward the end-to-end optimization of particle physics instruments
                                                                with differentiable programming</b></i>, Dorigo et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2023.06-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>AI meets physics: a comprehensive survey</b></i>, Jiao et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Artificial intelligence for partial differential equations in
                                                                computational mechanics: A review</b></i>, Wang et al.,
                                                <a href="https://arxiv.org/abs/2410.19843" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>When physics meets machine learning: A survey of physics-informed
                                                                machine learning</b></i>, Meng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Automated Law Discovery</b>
                                <ul>
                                        <li><i><b>LLM-SR: Scientific Equation Discovery via Programming with Large
                                                                Language Models</b></i>, Shojaee et al., <a
                                                        href="https://openreview.net/forum?id=m2nmp8P5in"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>LLM-Feynman: Leveraging Large Language Models for Universal Scientific
                                                                Formula and Theory Discovery</b></i>, Song et al., <a
                                                        href="https://arxiv.org/abs/2503.06512" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AI-Newton: A Concept-Driven Physical Law Discovery System without
                                                                Prior Physical Knowledge</b></i>, Fang et al., <a
                                                        href="https://arxiv.org/abs/2504.01538" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MLLM-based Discovery of Intrinsic Coordinates and Governing Equations
                                                                from High-Dimensional Data</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2505.11940" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLM-SRBench: A New Benchmark for Scientific Equation Discovery with
                                                                Large Language Models</b></i>, Shojaee et al., <a
                                                        href="https://openreview.net/forum?id=SyQPiZJVWY"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from
                                                                Data and Experience</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2506.04282" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Physical World Simulation</b>
                                <ul>
                                        <li><i><b>Interaction networks for learning about objects, relations and
                                                                physics</b></i>, Battaglia et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2016-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>End-to-end differentiable physics for learning and control</b></i>, de
                                                Avila Belbute-Peres et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2018-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Physics-informed neural networks: A deep learning framework for
                                                                solving forward and inverse problems involving nonlinear
                                                                partial differential equations</b></i>, Raissi et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2019.02-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Hamiltonian neural networks</b></i>, Greydanus et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2019-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Lagrangian neural networks</b></i>, Cranmer et al., <a
                                                        href="https://arxiv.org/abs/2003.04630" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2020.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Physics-informed neural networks and extensions</b></i>, Raissi et
                                                al., <a href="https://arxiv.org/abs/2408.16806" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="ai-for-social-science-research">6.3 AI for Social Science Research</h3>
                                <h4 id="ai-for-psychology-research">6.3.6 AI for Psychology Research</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Automating psychological hypothesis generation with AI: when large
                                                                language models meet causal graph</b></i>, Tong et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Can Large Language Models Understand You Better? An MBTI Personality
                                                                Detection Dataset Aligned with Population
                                                                Traits</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2412.12510" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Experiment Workflow Automation and Simulation.</b>
                                <ul>
                                        <li><i><b>Using cognitive psychology to understand GPT-3</b></i>, Binz et al.,
                                                <a href="http://dx.doi.org/10.1073/pnas.2218523120" target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.02-blue"
                                                                alt="PDF Badge"></a>
                                        </li>
                                        <li><i><b>Can AI language models replace human participants?</b></i>, Dillion et
                                                al., <a href="https://www.sciencedirect.com/science/article/pii/S1364661323000980"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>The emergence of economic rationality of GPT</b></i>, Chen et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2023.12-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>AI-experiments in education: An AI-driven randomized controlled trial
                                                                for higher education research</b></i>, Cingillioglu et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.00-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>RAISE: A New Method to Develop Experimental Stimuli for Advertising
                                                                Research with Image Generative Artificial
                                                                Intelligence</b></i>, Zamudio et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Frontiers: Can Large Language Models Capture Human
                                                                Preferences?</b></i>, Goli et al., <a
                                                        href="https://doi.org/10.1287/mksc.2023.0306"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.04-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Testing theory of mind in large language models and humans</b></i>,
                                                Strachan et al., <a
                                                        href="https://www.nature.com/articles/s41562-024-01895-1"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Do large language models show decision heuristics similar to humans? A
                                                                case study using GPT-3.5.</b></i>, Suri et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Towards a client-centered assessment of llm therapists by client
                                                                simulation</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2406.12266" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Interactive agents: Simulating counselor-client psychological
                                                                counseling via role-playing llm-to-llm
                                                                interactions</b></i>, Qiu et al., <a
                                                        href="https://arxiv.org/abs/2408.15787" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can AI Replace Human Subjects? A Large-Scale Replication of
                                                                Psychological Experiments with LLMs</b></i>, Cui et al.,
                                                <a href="https://arxiv.org/abs/2409.00128" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                </ul>

                                <b>Human-AI Trust and Safety Design.</b>
                                <ul>
                                        <li><i><b>MMSD2. 0: Towards a reliable multi-modal sarcasm detection
                                                                system</b></i>, Qin et al., <a
                                                        href="https://arxiv.org/abs/2307.07135" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Developing trustworthy artificial intelligence: insights from research
                                                                on interpersonal, human-automation, and human-AI
                                                                trust</b></i>, Li et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>From Lived Experience to Insight: Unpacking the Psychological Risks of
                                                                Using AI Conversational Agents</b></i>, Chandra et al.,
                                                <a href="https://arxiv.org/abs/2412.07951" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                </ul>

                                <b>Psychological Interventions.</b>
                                <ul>
                                        <li><i><b>Using cognitive psychology to understand GPT-3</b></i>, Binz et al.,
                                                <a href="http://dx.doi.org/10.1073/pnas.2218523120" target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.02-blue"
                                                                alt="PDF Badge"></a>
                                        </li>
                                        <li><i><b>Can AI language models replace human participants?</b></i>, Dillion et
                                                al., <a href="https://www.sciencedirect.com/science/article/pii/S1364661323000980"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Human-like intuitive behavior and reasoning biases emerged in large
                                                                language models but disappeared in ChatGPT</b></i>,
                                                Hagendorff et al., <a
                                                        href="http://dx.doi.org/10.1038/s43588-023-00527-x"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.10-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Large Language Models Can Enable Inductive Thematic Analysis of a
                                                                Social Media Corpus in a Single Prompt: Human Validation
                                                                Study</b></i>, Deiner et al., <a
                                                        href="https://doi.org/10.2196/59641" target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Crafting clarity: Leveraging large language models to decode consumer
                                                                reviews</b></i>, Praveen et al., <a
                                                        href="https://www.sciencedirect.com/science/article/pii/S0969698924002716"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>ChatGPT for Textual Analysis? How to Use Generative LLMs in Accounting
                                                                Research</b></i>, de Kok et al., <a
                                                        href="https://doi.org/10.1287/mnsc.2023.03253"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.01-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>The use of artificial intelligence in psychotherapy: development of
                                                                intelligent therapeutic systems</b></i>, Spytska et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Randomized trial of a generative ai chatbot for mental health
                                                                treatment</b></i>, Heinz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large language models as mental health resources: Patterns of use in
                                                                the united states</b></i>, Rousmaniere et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Large Language Models Pass the Turing Test</b></i>, Jones et al., <a
                                                        href="https://arxiv.org/abs/2503.23674" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Experiential Narratives in Marketing: A Comparison of Generative AI
                                                                and Human Content</b></i>, Wen et al., <a
                                                        href="https://doi.org/10.1177/07439156241297973"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.10-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <h4 id="ai-for-sociology-research">6.3.7 AI for Sociology Research</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Ethnography and Machine Learning: Synergies and New
                                                                Directions</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2412.06087" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Machine-assisted quantitizing designs: augmenting humanities and
                                                                social sciences with artificial intelligence</b></i>,
                                                Karjus et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Agent-Enhanced Large Language Models for Researching Political
                                                                Institutions</b></i>, Loffredo et al., <a
                                                        href="https://arxiv.org/abs/2503.13524" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Reimagining urban science: Scaling causal inference with large
                                                                language models</b></i>, Xia et al., <a
                                                        href="https://arxiv.org/abs/2504.12345" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>AI-Assisted Experimental and Interview Studies.</b>
                                <ul>
                                        <li><i><b>Automated social science: Language models as scientist and
                                                                subjects</b></i>, Manning et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Step Further Towards Automated Social Science: An AI-Powered Interview
                                                                Platform</b></i>, Liu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Large-Scale Simulation of Social Phenomena.</b>
                                <ul>
                                        <li><i><b>RAISE: A New Method to Develop Experimental Stimuli for Advertising
                                                                Research with Image Generative Artificial
                                                                Intelligence</b></i>, Zamudio et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Cultural evolution in populations of Large Language Models</b></i>,
                                                Perez et al., <a href="https://arxiv.org/abs/2403.08882"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Economic Anthropology in the Era of Generative Artificial
                                                                Intelligence</b></i>, Sheldon et al., <a
                                                        href="https://arxiv.org/abs/2410.15238" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Malinowski in the Age of AI: Can large language models create a text
                                                                game based on an anthropological classic?</b></i>,
                                                Hoffmann et al., <a href="https://arxiv.org/abs/2410.20536"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AdaSociety: An Adaptive Environment with Social Structures for
                                                                Multi-Agent Decision-Making</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2411.03865" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ResearchTown: Simulator of Human Research Community</b></i>, Yu et
                                                al., <a href="https://arxiv.org/abs/2412.17767" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Simulating cooperative prosocial behavior with multi-agent LLMs:
                                                                Evidence and mechanisms for AI agents to inform policy
                                                                decisions</b></i>, Sreedhar et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Predicting Field Experiments with Large Language Models</b></i>, Chen
                                                et al., <a href="https://arxiv.org/abs/2504.01167" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Language Models Surface the Unwritten Code of Science and
                                                                Society</b></i>, Bao et al., <a
                                                        href="https://arxiv.org/abs/2505.18942" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Potential Risks Discussion.</b>
                                <ul>
                                        <li><i><b>Automated social science: Language models as scientist and
                                                                subjects</b></i>, Manning et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>ChatGPT as research scientist: probing GPT’s capabilities as a
                                                                research librarian, research ethicist, data generator,
                                                                and data predictor</b></i>, Lehr et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Predicting Results of Social Science Experiments Using Large Language
                                                                Models</b></i>, Luke et al., <a
                                                        href="https://samim.io/dl/Predicting%20results%20of%20social%20science%20experiments%20using%20large%20language%20models.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>
                                <h2 id="resources">7. Resources</h2>


                                <h3 id="ai-for-academic-peer-reviewing">7.1 AI for Academic Peer Reviewing</h3>
                                <ul>
                                        <li><i><b>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP
                                                                Applications</b></i>, Kang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2018.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Citetracked: A longitudinal dataset of peer reviews and
                                                                citations</b></i>, Plank et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2019.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>COMPARE: a taxonomy and dataset of comparison discussions in peer
                                                                reviews</b></i>, Singh et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Peer review analyze: A novel benchmark resource for computational
                                                                analysis of peer reviews</b></i>, Ghosal et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Reviewergpt? an exploratory study on using large language models for
                                                                paper reviewing</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2306.00622" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>NLPeer: A Unified Resource for the Computational Study of Peer
                                                                Review</b></i>, Dycke et al., <a
                                                        href="https://aclanthology.org/2023.acl-long.277/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2023.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Moprd: A multidisciplinary open peer review dataset</b></i>, Lin et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.09-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The Open Review-Based (ORB) dataset: Towards Automatic Assessment of
                                                                Scientific Papers and Experiment Proposals in
                                                                High-Energy Physics</b></i>, Szumega et al., <a
                                                        href="https://arxiv.org/abs/2312.04576" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Pre: A peer review based large language model evaluator</b></i>, Chu
                                                et al., <a href="https://arxiv.org/abs/2401.15641" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Is LLM a reliable reviewer? A comprehensive evaluation of LLM on
                                                                automatic paper reviewing tasks</b></i>, Zhou et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>PolitePEER: does peer review hurt? A dataset to gauge politeness
                                                                intensity in the peer reviews</b></i>, Bharti et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>RelevAI-Reviewer: A Benchmark on AI Reviewers for Survey Paper
                                                                Relevance</b></i>, Couto et al., <a
                                                        href="https://arxiv.org/abs/2406.10294" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Peer review as a multi-turn and long-context dialogue with role-based
                                                                interactions</b></i>, Tan et al., <a
                                                        href="https://arxiv.org/abs/2406.05688" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific
                                                                workflows</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2406.06357" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scientific opinion summarization: Paper meta-review generation
                                                                dataset, methods, and evaluation</b></i>, Zeng et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>Can large language models provide useful feedback on research papers?
                                                                A large-scale empirical analysis</b></i>, Liang et al.,
                                                <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey"
                                                        alt="Other Source Badge">
                                        </li>
                                        <li><i><b>An Analysis of Tasks and Datasets in Peer Reviewing</b></i>,
                                                Staudinger et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>PeerArg: Argumentative Peer Review with LLMs</b></i>, Sukpanichnant et
                                                al., <a href="https://arxiv.org/abs/2409.16813" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Enhancing peer review efficiency: A mixed-methods analysis of
                                                                artificial intelligence-assisted reviewer selection
                                                                across academic disciplines</b></i>, Farber et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Automatic Large Language Model Evaluation via Peer Review</b></i>, Chu
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>AAAR-1.0: Assessing AI's Potential to Assist Research</b></i>, Lou et
                                                al., <a href="https://arxiv.org/abs/2410.22394" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Is your paper being reviewed by an llm? investigating ai text
                                                                detectability in peer review</b></i>, Yu et al., <a
                                                        href="https://arxiv.org/abs/2410.03019" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>WithdrarXiv: A Large-Scale Dataset for Retraction Study</b></i>, Rao
                                                et al., <a href="https://arxiv.org/abs/2412.03775" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>OpenReviewer: A Specialized Large Language Model for Generating
                                                                Critical Scientific Paper Reviews</b></i>, Idahl et al.,
                                                <a href="https://arxiv.org/abs/2412.11948" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM
                                                                Reviews</b></i>, Shin et al., <a
                                                        href="https://arxiv.org/abs/2502.17086" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PeerQA: A Scientific Question Answering Dataset from Peer
                                                                Reviews</b></i>, Baumg{\"a}rtner et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Revieweval: An evaluation framework for ai-generated reviews</b></i>,
                                                Kirtani et al., <a href="https://arxiv.org/abs/2502.11736"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer
                                                                Reviews</b></i>, Purkayastha et al., <a
                                                        href="https://arxiv.org/abs/2504.11042" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>When AI co-scientists fail: SPOT-a benchmark for automated
                                                                verification of scientific research</b></i>, Son et al.,
                                                <a href="https://arxiv.org/abs/2505.11855" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Re <sup>2</sup>: A Consistency-ensured Dataset for Full-stage Peer
                                                                Review and Multi-turn Rebuttal Discussions</b></i>,
                                                Zhang et al., <a href="https://arxiv.org/abs/2505.07920"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>PaperEval: A universal, quantitative, and explainable paper evaluation
                                                                method powered by a multi-agent system</b></i>, Huang et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.11-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="application-of-ai-for-research">7.1.1 Application of AI for Research</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Comprehensive inventory of methane emissions from the U.S. oil and gas
                                                                industry</b></i>, Chen et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>DGPCD: a high-precision point cloud dataset of Dougong in ancient
                                                                Chinese architecture</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>



                                <h3 id="ai-for-academic-survey">7.2 AI for Academic Survey</h3>
                                </ul>

                                <ul>
                                        <li><i><b>Ms2: Multi-document summarization of medical studies</b></i>, DeYoung
                                                et al., <a href="https://arxiv.org/abs/2104.06486" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Generating (factual?) narrative summaries of rcts: Experiments with
                                                                neural multi-document summarization</b></i>, Wallace et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Overview of MSLR2022: A shared task on multi-document summarization
                                                                for literature reviews</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Generating a structured summary of numerous academic papers: Dataset
                                                                and method</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2302.04580" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciReviewGen: a large-scale dataset for automatic literature review
                                                                generation</b></i>, Kasanishi et al., <a
                                                        href="https://arxiv.org/abs/2305.15186" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SurveySum: A Dataset for Summarizing Multiple Scientific Articles into
                                                                a Survey Section</b></i>, Fernandes et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.01-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>OAG-Bench: A Human-Curated Benchmark for Academic Graph
                                                                Mining</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2402.15810" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>OARelatedWork: A Large-Scale Dataset of Related Work Sections with
                                                                Full-texts from Open Access Sources</b></i>, Docekal et
                                                al., <a href="https://arxiv.org/abs/2405.01930" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autosurvey: Large language models can automatically write
                                                                surveys</b></i>, Wang et al., <img
                                                        src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>SurveyX: Academic Survey Automation via Large Language Models</b></i>,
                                                Liang et al., <a href="https://arxiv.org/abs/2502.14776"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and
                                                                Multi-dimensional Evaluation for Automated Survey
                                                                Writing</b></i>, Yan et al., <a
                                                        href="https://arxiv.org/abs/2503.04629" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Browsecomp: A simple yet challenging benchmark for browsing
                                                                agents</b></i>, Wei et al., <a
                                                        href="https://arxiv.org/abs/2504.12516" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLM </sup>times</sup> MapReduce-V2: Entropy-Driven Convolutional
                                                                Test-Time Scaling for Generating Long-Form Articles from
                                                                Extremely Long Resources</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2504.05732" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AcademicBrowse: Benchmarking Academic Browse Ability of LLMs</b></i>,
                                                Zhou et al., <a href="https://arxiv.org/abs/2506.13784"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="ai-for-academic-writing">7.3 AI for Academic Writing</h3>
                                <h4 id="semi-automatic-academic-writing">7.3.2 Semi-Automatic Academic Writing</h4>
                                </ul>

                                <b>Assistance After Manuscript Completion.</b>
                                <ul>
                                        <li><i><b>WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling
                                                                language and discourse</b></i>, Faruqui et al., <a
                                                        href="https://arxiv.org/abs/1808.09422" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2018.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Learning to split and rephrase from Wikipedia edit history</b></i>,
                                                Botha et al., <a href="https://arxiv.org/abs/1808.09468"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2018.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Diamonds in the rough: Generating fluent sentences from early-stage
                                                                drafts for academic writing assistance</b></i>, Ito et
                                                al., <a href="https://arxiv.org/abs/1910.09180" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Neural Automated Writing Evaluation with Corrective Feedback</b></i>,
                                                Wang et al., <a href="https://arxiv.org/abs/2402.17613"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AAAR-1.0: Assessing AI's Potential to Assist Research</b></i>, Lou et
                                                al., <a href="https://arxiv.org/abs/2410.22394" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Paper2Poster: Towards Multimodal Poster Automation from Scientific
                                                                Papers</b></i>, Pang et al., <a
                                                        href="https://arxiv.org/abs/2505.21497" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>The usage of a transformer based and artificial intelligence driven
                                                                multidimensional feedback system in english writing
                                                                instruction</b></i>, Zheng et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Assistance During Manuscript Preparation.</b>
                                <ul>
                                        <li><i><b>LLM-Rubric: A Multidimensional, Calibrated Approach to Automated
                                                                Evaluation of Natural Language Texts</b></i>, Hashemi et
                                                al., <a href="https://aclanthology.org/2024.acl-long.745/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>MoDeST: A dataset for Multi Domain Scientific Title
                                                                Generation</b></i>, Bölücü et al., <a
                                                        href="https://www.sciencedirect.com/science/article/pii/S0950705125006033"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.06-blue"
                                                                alt="PDF Badge"></a></li>
                                </ul>

                                <b>Assistance During Manuscript Writing</b>
                                <ul>
                                        <li><i><b>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document
                                                                Understanding</b></i>, Wright et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2021.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Figgen: Text to scientific figure generation</b></i>, Rodriguez et
                                                al., <a href="https://arxiv.org/abs/2306.00800" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scicapenter: Supporting caption composition for scientific figures
                                                                with machine-generated captions and ratings</b></i>, Hsu
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Figuring out Figures: Using Textual References to Caption Scientific
                                                                Figures</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2407.11008" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CiteBART: Learning to Generate Citations for Local Citation
                                                                Recommendation</b></i>, {\c{C}}elik et al., <a
                                                        href="https://arxiv.org/abs/2412.17534" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>TikZero: Zero-Shot Text-Guided Graphics Program Synthesis</b></i>,
                                                Belouadi et al., <a href="https://arxiv.org/abs/2503.11509"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Futuregen: Llm-rag approach to generate the future work of scientific
                                                                article</b></i>, Azher et al., <a
                                                        href="https://arxiv.org/abs/2503.16561" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ScholarCopilot: Training Large Language Models for Academic Writing
                                                                with Accurate Citations</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2504.00824" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic
                                                                Paper Revision</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2505.11336" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="ai-for-scientific-comprehension">7.4 AI for Scientific Comprehension</h3>
                                <h4 id="table-chart-scientific-comprehension">7.4.3 Table & Chart Scientific
                                        Comprehension</h4>
                                </ul>

                                <ul>
                                        <li><i><b>ChartQA: A Benchmark for Question Answering about Charts with Visual
                                                                and Logical Reasoning</b></i>, Masry et al., <a
                                                        href="https://aclanthology.org/2022.findings-acl.177/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2022.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Chartx & chartvlm: A versatile benchmark and foundation model for
                                                                complicated chart reasoning</b></i>, Xia et al., <a
                                                        href="https://arxiv.org/abs/2402.12185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Table Meets LLM: Can Large Language Models Understand Structured Table
                                                                Data? A Benchmark and Empirical Study</b></i>, Sui et
                                                al., <a href="https://doi.org/10.1145/3616855.3635752"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.03-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>NovaChart: A Large-scale Dataset towards Chart Understanding and
                                                                Generation of Multimodal Large Language Models</b></i>,
                                                Hu et al., <a href="https://openreview.net/forum?id=PTYL6011vp"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.10-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal
                                                                LLMs</b></i>, Wang et al., <a
                                                        href="https://proceedings.neurips.cc/paper_files/paper/2024/file/cdf6f8e9fd9aeaf79b6024caec24f15b-Paper-Datasets_and_Benchmarks_Track.pdf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.12-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>The Mighty ToRR: A Benchmark for Table Reasoning and
                                                                Robustness</b></i>, Ashury-Tahan et al., <a
                                                        href="https://arxiv.org/abs/2502.19412" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Tablebench: A comprehensive and complex benchmark for table question
                                                                answering</b></i>, Wu et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <h4 id="textual-scientific-comprehension">7.4.4 Textual Scientific Comprehension</h4>
                                </ul>

                                <ul>
                                        <li><i><b>Pubmedqa: A dataset for biomedical research question
                                                                answering</b></i>, Jin et al., <a
                                                        href="https://arxiv.org/abs/1909.06146" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2019.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Medmcqa: A large-scale multi-subject multi-choice dataset for medical
                                                                domain question answering</b></i>, Pal et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.04-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>CoQUAD: a COVID-19 question answering dataset system, facilitating
                                                                research, benchmarking, and practice</b></i>, Raza et
                                                al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Scienceqa: A novel resource for question answering on scholarly
                                                                articles</b></i>, Saikh et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2022.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Clam: Selective clarification for ambiguous questions with generative
                                                                language models</b></i>, Kuhn et al., <a
                                                        href="https://arxiv.org/abs/2212.07769" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2022.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>BioASQ-QA: A manually curated corpus for Biomedical Question
                                                                Answering</b></i>, Krithara et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>The sciqa scientific question answering benchmark for scholarly
                                                                knowledge</b></i>, Auer et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Theoremqa: A theorem-driven question answering dataset</b></i>, Chen
                                                et al., <a href="https://arxiv.org/abs/2305.12524" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scibench: Evaluating college-level scientific problem-solving
                                                                abilities of large language models</b></i>, Wang et al.,
                                                <a href="https://arxiv.org/abs/2307.10635" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.07-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>What if: Generating code to answer simulation questions in chemistry
                                                                texts</b></i>, Peretz et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2023.07-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Enabling Language Models to Implicitly Learn Self-Improvement</b></i>,
                                                Wang et al., <a href="https://arxiv.org/abs/2310.00898"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Paperqa: Retrieval-augmented generative agent for scientific
                                                                research</b></i>, L{\'a}la et al., <a
                                                        href="https://arxiv.org/abs/2312.07559" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciglm: Training scientific language models with self-reflective
                                                                instruction annotation and tuning</b></i>, Zhang et al.,
                                                <a href="https://arxiv.org/abs/2401.07950" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Generating Multiple Choice Questions from Scientific Literature via
                                                                Large Language Models</b></i>, Luo et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.02-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Biomedlm: A 2.7 b parameter language model trained on biomedical
                                                                text</b></i>, Bolton et al., <a
                                                        href="https://arxiv.org/abs/2403.18421" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciQAG: A Framework for Auto-Generated Science Question Answering
                                                                Dataset with Fine-grained Evaluation</b></i>, Wan et
                                                al., <a href="https://arxiv.org/abs/2405.09939" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>M <sup>3</sup> CoT: A Novel Benchmark for Multi-Domain Multi-step
                                                                Multi-modal Chain-of-Thought</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2405.16473" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scifibench: Benchmarking large multimodal models for scientific figure
                                                                interpretation</b></i>, Roberts et al., <a
                                                        href="https://arxiv.org/abs/2405.08807" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sciknoweval: Evaluating multi-level scientific knowledge of large
                                                                language models</b></i>, Feng et al., <a
                                                        href="https://arxiv.org/abs/2406.09098" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.06-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for
                                                                Biomedical Science</b></i>, Lin et al., <a
                                                        href="https://arxiv.org/abs/2407.00466" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scholarchemqa: Unveiling the power of language models in chemical
                                                                research question answering</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2407.16931" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mmsci: A dataset for graduate-level multi-discipline multimodal
                                                                scientific understanding</b></i>, Li et al., <a
                                                        href="https://arxiv.org/abs/2407.04903" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SPIQA: A Dataset for Multimodal Question Answering on Scientific
                                                                Papers</b></i>, Pramanick et al., <a
                                                        href="https://openreview.net/forum?id=h3lddsY5nf"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.07-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of
                                                                Large Vision-Language Models</b></i>, Li et al., <a
                                                        href="https://aclanthology.org/2024.acl-long.775/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>SceMQA: A Scientific College Entrance Level Multimodal Question
                                                                Answering Benchmark</b></i>, Liang et al., <a
                                                        href="https://aclanthology.org/2024.acl-short.11/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.08-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Language agents achieve superhuman synthesis of scientific
                                                                knowledge</b></i>, Skarlinski et al., <a
                                                        href="https://arxiv.org/abs/2409.13740" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Fine-Tuning Large Language Models for Scientific Text Classification:
                                                                A Comparative Study</b></i>, Rostam et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.10-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a
                                                                global perspective</b></i>, Yang et al., <a
                                                        href="https://arxiv.org/abs/2410.17600" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for
                                                                Evaluating Foundation Models</b></i>, Li et al., <a
                                                        href="https://aclanthology.org/2024.findings-emnlp.904/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>SciDQA: A Deep Reading Comprehension Dataset over Scientific
                                                                Papers</b></i>, Singh et al., <a
                                                        href="https://arxiv.org/abs/2411.05338" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.11-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciAgent: Tool-augmented Language Models for Scientific
                                                                Reasoning</b></i>, Ma et al., <a
                                                        href="https://aclanthology.org/2024.emnlp-main.880/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2024.11-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>SciRIFF: A Resource to Enhance Language Model Instruction-Following
                                                                over Scientific Literature</b></i>, Wadden et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He
                                                et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>BioMaze: Benchmarking and Enhancing Large Language Models for
                                                                Biological Pathway Reasoning</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2502.16660" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AutoPaperBench: An MLLM-Based Framework for Automatic Generation of
                                                                Paper Understanding Evaluation Benchmarks</b></i>, Kim
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>FRAME: Feedback-Refined Agent Methodology for Enhancing Medical
                                                                Research Insights</b></i>, Yu et al., <a
                                                        href="https://arxiv.org/abs/2505.04649" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context
                                                                Understanding in Large Language Models</b></i>, Yu et
                                                al., <a href="https://arxiv.org/abs/2505.15094" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>EarthSE: A Benchmark Evaluating Earth Scientific Exploration
                                                                Capability for Large Language Models</b></i>, Xu et al.,
                                                <a href="https://arxiv.org/abs/2505.17139" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Scaling Physical Reasoning with the PHYSICS Dataset</b></i>, Zheng et
                                                al., <a href="https://arxiv.org/abs/2506.00022" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>



                                <h3 id="ai-for-scientific-discovery">7.5 AI for Scientific Discovery</h3>
                                </ul>

                                <ul>
                                        <li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via
                                                                Inspiration-Based Task Decomposition</b></i>, Liu et
                                                al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Experiment Conduction</b>
                                <ul>
                                        <li><i><b>Mlagentbench: Evaluating language agents on machine learning
                                                                experimentation</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2310.03302" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Infiagent-dabench: Evaluating agents on data analysis tasks</b></i>,
                                                Hu et al., <a href="https://arxiv.org/abs/2401.05507"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.01-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>DSBench: How Far Are Data Science Agents to Becoming Data Science
                                                                Experts?</b></i>, Jing et al., <a
                                                        href="https://arxiv.org/abs/2409.07703" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mle-bench: Evaluating machine learning agents on machine learning
                                                                engineering</b></i>, Chan et al., <a
                                                        href="https://arxiv.org/abs/2410.07095" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mlgym: A new framework and benchmark for advancing ai research
                                                                agents</b></i>, Nathani et al., <a
                                                        href="https://arxiv.org/abs/2502.14499" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MLRC-Bench: Can Language Agents Solve Machine Learning Research
                                                                Challenges?</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2504.09702" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scireplicate-bench: Benchmarking llms in agent-driven algorithmic
                                                                reproduction from research papers</b></i>, Xiang et al.,
                                                <a href="https://arxiv.org/abs/2504.00255" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>Can AI Agents Design and Implement Drug Discovery Pipelines?</b></i>,
                                                Smbatyan et al., <a href="https://arxiv.org/abs/2504.19912"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>EXP-Bench: Can AI Conduct AI Research Experiments?</b></i>, Kon et
                                                al., <a href="https://arxiv.org/abs/2505.24785" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scienceboard: Evaluating multimodal autonomous agents in realistic
                                                                scientific workflows</b></i>, Sun et al., <a
                                                        href="https://arxiv.org/abs/2505.19897" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper
                                                                Lineage</b></i>, Zhao et al., <a
                                                        href="https://arxiv.org/abs/2505.20662" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning
                                                                Research</b></i>, Chen et al., <a
                                                        href="https://arxiv.org/abs/2505.19955" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Autobio: A simulation and benchmark for robotic automation in digital
                                                                biology laboratory</b></i>, Lan et al., <a
                                                        href="https://arxiv.org/abs/2505.14030" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine
                                                                Learning Research Code</b></i>, Hua et al., <a
                                                        href="https://arxiv.org/abs/2506.02314" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Experiment Design</b>
                                <ul>
                                        <li><i><b>Benchmarking compound activity prediction for real-world drug
                                                                discovery applications</b></i>, Tian et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.06-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A bioactivity foundation model using pairwise meta-learning</b></i>,
                                                Feng et al., <img src="https://img.shields.io/badge/Nature-2024-green"
                                                        alt="Nature Badge"></li>
                                        <li><i><b>BioProBench: Comprehensive Dataset and Benchmark in Biological
                                                                Protocol Understanding and Reasoning</b></i>, Liu et
                                                al., <a href="https://arxiv.org/abs/2505.07889" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with
                                                                Physician Validation</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2506.04078" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.06-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Experimental Analysis</b>
                                <ul>
                                        <li><i><b>Microvqa: A multimodal reasoning benchmark for microscopy-based
                                                                scientific research</b></i>, Burgess et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2025.03-lightgrey"
                                                        alt="Other Source Badge"></li>
                                </ul>

                                <b>Full Automatic Discovery</b>
                                <ul>
                                        <li><i><b>Ds-agent: Automated data science by empowering large language models
                                                                with case-based reasoning</b></i>, Guo et al., <a
                                                        href="https://arxiv.org/abs/2402.17453" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Discoverybench: Towards data-driven discovery with large language
                                                                models</b></i>, Majumder et al., <a
                                                        href="https://arxiv.org/abs/2407.01725" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.07-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Blade: Benchmarking language model agents for data-driven
                                                                science</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2408.09667" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Scienceagentbench: Toward rigorous assessment of language agents for
                                                                data-driven scientific discovery</b></i>, Chen et al.,
                                                <a href="https://arxiv.org/abs/2410.05080" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>DISCOVERYWORLD: A virtual environment for developing and evaluating
                                                                automated scientific discovery agents</b></i>, Jansen et
                                                al., <img src="https://img.shields.io/badge/NeurIPS-2024-green"
                                                        alt="NeurIPS Badge"></li>
                                        <li><i><b>Curie: Toward rigorous and automated scientific experimentation with
                                                                ai agents</b></i>, Kon et al., <a
                                                        href="https://arxiv.org/abs/2502.16069" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>A vision for auto research with llm agents</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2504.18765" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can AI Agents Design and Implement Drug Discovery Pipelines?</b></i>,
                                                Smbatyan et al., <a href="https://arxiv.org/abs/2504.19912"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Llm-srbench: A new benchmark for scientific equation discovery with
                                                                large language models</b></i>, Shojaee et al., <a
                                                        href="https://arxiv.org/abs/2504.10415" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Towards llm agents for earth observation</b></i>, Kao et al., <a
                                                        href="https://arxiv.org/abs/2504.12110" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Benchmarking AI scientists in omics data-driven biological
                                                                research</b></i>, Luo et al., <a
                                                        href="https://arxiv.org/abs/2505.08341" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Idea Mining</b>
                                <ul>
                                        <li><i><b>OAG-Bench: A Human-Curated Benchmark for Academic Graph
                                                                Mining</b></i>, Zhang et al., <a
                                                        href="https://arxiv.org/abs/2402.15810" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can Large Language Models Unlock Novel Scientific Research
                                                                Ideas?</b></i>, Kumar et al., <a
                                                        href="https://arxiv.org/abs/2409.06185" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>LiveIdeaBench: Evaluating LLMs' Scientific Creativity and Idea
                                                                Generation with Minimal Context</b></i>, Ruan et al., <a
                                                        href="https://arxiv.org/abs/2412.17596" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Large Language Models for Rediscovering Unseen Chemistry Scientific
                                                                Hypotheses</b></i>, Yang et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Learning to Generate Research Idea with Dynamic Control</b></i>, Li et
                                                al., <a href="https://arxiv.org/abs/2412.14626" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Structuring Scientific Innovation: A Framework for Modeling and
                                                                Discovering Impactful Knowledge Combinations</b></i>,
                                                Chen et al., <a href="https://arxiv.org/abs/2503.18865"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via
                                                                Inspiration-Based Task Decomposition</b></i>, Liu et
                                                al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.03-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Ai idea bench 2025: Ai research idea generation benchmark</b></i>, Qiu
                                                et al., <a href="https://arxiv.org/abs/2504.14191" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Sparks of science: Hypothesis generation using structured paper
                                                                data</b></i>, O'Neill et al., <a
                                                        href="https://arxiv.org/abs/2504.12976" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Spark: A System for Scientifically Creative Idea Generation</b></i>,
                                                Sanyal et al., <a href="https://arxiv.org/abs/2504.20090"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Improving Research Idea Generation Through Data: An Empirical
                                                                Investigation in Social Science</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.21396" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>CHIMERA: A Knowledge Base of Idea Recombination in Scientific
                                                                Literature</b></i>, Sternlicht et al., <a
                                                        href="https://arxiv.org/abs/2505.20779" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Novelty & Significant Assesment</b>
                                <ul>
                                        <li><i><b>Blade: Benchmarking language model agents for data-driven
                                                                science</b></i>, Gu et al., <a
                                                        href="https://arxiv.org/abs/2408.09667" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Empowering AI as Autonomous Researchers: Evaluating LLMs in Generating
                                                                Novel Research Ideas through Automated Metrics</b></i>,
                                                Dasgupta et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>LLMs Tackle Meta-Analysis: Automating Scientific Hypothesis Generation
                                                                with Statistical Rigor</b></i>, Lin et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.12-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>A Hierarchical Framework for Measuring Scientific Paper Innovation via
                                                                Large Language Models</b></i>, Tan et al., <a
                                                        href="https://arxiv.org/abs/2504.14620" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Hypobench: Towards systematic and principled benchmarking for
                                                                hypothesis generation</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2504.11524" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.04-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Evaluating and Enhancing Large Language Models for Novelty Assessment
                                                                in Scholarly Publications</b></i>, Lin et al., <a
                                                        href="https://aclanthology.org/2025.aisd-main.5/"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/PDF-2025.05-blue"
                                                                alt="PDF Badge"></a></li>
                                        <li><i><b>Harnessing Large Language Models for Scientific Novelty
                                                                Detection</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2505.24615" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>

                                <b>Theory Analysis</b>
                                <ul>
                                        <li><i><b>Minif2f: a cross-system benchmark for formal olympiad-level
                                                                mathematics</b></i>, Zheng et al., <a
                                                        href="https://arxiv.org/abs/2109.00110" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2021.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>FactKG: Fact verification via reasoning on knowledge graphs</b></i>,
                                                Kim et al., <a href="https://arxiv.org/abs/2305.06590"
                                                        target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.05-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Investigating zero-and few-shot generalization in fact
                                                                verification</b></i>, Pan et al., <a
                                                        href="https://arxiv.org/abs/2309.09444" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Fimo: A challenge formal dataset for automated theorem
                                                                proving</b></i>, Liu et al., <a
                                                        href="https://arxiv.org/abs/2309.04295" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2023.09-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Can Large Language Models Detect Misinformation in Scientific News
                                                                Reporting?</b></i>, Cao et al., <a
                                                        href="https://arxiv.org/abs/2402.14268" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Mustard: Mastering uniform synthesis of theorem and proof
                                                                data</b></i>, Huang et al., <a
                                                        href="https://arxiv.org/abs/2402.08957" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>MAGIC: Multi-Argument Generation with Self-Refinement for Domain
                                                                Generalization in Automatic Fact-Checking</b></i>, Kao
                                                et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.05-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Zero-shot scientific claim verification using LLMs and citation
                                                                text</b></i>, Alvarez et al., <img
                                                        src="https://img.shields.io/badge/Other Source-2024.08-lightgrey"
                                                        alt="Other Source Badge"></li>
                                        <li><i><b>Grounding fallacies misrepresenting scientific publications in
                                                                evidence</b></i>, Glockner et al., <a
                                                        href="https://arxiv.org/abs/2408.12812" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.08-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>Augmenting the Veracity and Explanations of Complex Fact Checking via
                                                                Iterative Self-Revision with LLMs</b></i>, Zhang et al.,
                                                <a href="https://arxiv.org/abs/2410.15135" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.10-red"
                                                                alt="arXiv Badge"></a>
                                        </li>
                                        <li><i><b>DEFAME: Dynamic Evidence-based FAct-checking with Multimodal
                                                                Experts</b></i>, Braun et al., <a
                                                        href="https://arxiv.org/abs/2412.10510" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2024.12-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>TheoremExplainAgent: Towards Video-based Multimodal Explanations for
                                                                LLM Theorem Understanding</b></i>, Ku et al., <a
                                                        href="https://arxiv.org/abs/2502.19400" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.02-red"
                                                                alt="arXiv Badge"></a></li>
                                        <li><i><b>BioDSA-1K: Benchmarking Data Science Agents for Biomedical
                                                                Research</b></i>, Wang et al., <a
                                                        href="https://arxiv.org/abs/2505.16100" target="_blank"><img
                                                                src="https://img.shields.io/badge/arXiv-2025.05-red"
                                                                alt="arXiv Badge"></a></li>
                                </ul>


                        </div>
                        </ul>
                </div>
                <div class="columns is-centered">
                        <div class="column is-9">
                        </div>
                </div>
                </div>
        </section>

        <section class="section" id="BibTeX">
                <div class="container is-max-desktop content">
                        <h2 class="title">BibTeX</h2>
                        <pre><code>BibTex Code Here</code></pre>
                </div>
        </section>
        <footer class="footer">
                <div class="container">
                        <div class="columns is-centered">
                                <div class="column is-8">
                                        <div class="content">

                                                <p>
                                                        This page was built using the <a
                                                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                                                target="_blank">Academic Project Page Template</a> which
                                                        was adopted from the <a href="https://nerfies.github.io"
                                                                target="_blank">Nerfies</a> project page.
                                                        You are free to borrow the source code of this website, we just
                                                        ask that you link back to this page in the footer. <br> This
                                                        website is licensed under a <a rel="license"
                                                                href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                target="_blank">Creative
                                                                Commons Attribution-ShareAlike 4.0 International
                                                                License</a>.
                                                </p>

                                        </div>
                                </div>
                        </div>
                </div>
        </footer>
</body>

</html>